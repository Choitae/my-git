{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "champion-timing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Physical devices cannot be modified after being initialized\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "# Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "# Memory growth must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "intellectual-rescue",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hellow World\n"
     ]
    }
   ],
   "source": [
    "print(\"Hellow World\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "native-attraction",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_dir = \"./dogs_dt\"\n",
    "for i in [\"train\", \"validataion\", \"test\"]:\n",
    "    new_dir = images_dir + \"/\" + \"{}\".format(i)\n",
    "    print(new_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "finite-laugh",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, shutil\n",
    "\n",
    "new_dogs_dir = \"./dogs_dt\"\n",
    "os.mkdir(new_dogs_dir)\n",
    "\n",
    "origin_dogs_dir = os.path.join(\"./images/Images\")\n",
    "for path, dir, files in os.walk(origin_dogs_dir):\n",
    "    if dir != []:\n",
    "        print(dir)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "composed-luther",
   "metadata": {},
   "outputs": [],
   "source": [
    "origin_dogs_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "strong-nelson",
   "metadata": {},
   "source": [
    "# 이미지 크롤링하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "demographic-information",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "with requests.get('https://www.istockphoto.com/kr/search/more-like-this/147877485?assettype=image&family=creative&mediatype=photography') as res:\n",
    "    soup= BeautifulSoup(res.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affiliated-clothing",
   "metadata": {},
   "outputs": [],
   "source": [
    "spot = \"bulldok\"\n",
    "os.mkdir(spot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adolescent-infrastructure",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib.request\n",
    "\n",
    "folderspot = \"./dogs/\"\n",
    "k = 1\n",
    "for i in range(4):\n",
    "        url = 'https://www.istockphoto.com/kr/search/more-like-this/147877485?assettype=image&family=creative&mediatype=photography'\n",
    "        new_url = url + \"&page={}\".format(i)\n",
    "        with requests.get(new_url) as res:\n",
    "            soup = BeautifulSoup(res.text, 'html.parser')\n",
    "            \n",
    "        big =  soup.find_all('img', class_=\"gallery-asset__thumb gallery-mosaic-asset__thumb\")\n",
    "\n",
    "        for i, img in enumerate(big):\n",
    "            src = img.get('src')\n",
    "            print(src)\n",
    "            urllib.request.urlretrieve(src, folderspot+ '{}.jpg'.format(k))\n",
    "            k += 1\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continuous-significance",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sudden-volunteer",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib.request\n",
    "\n",
    "# image_down_load : 이미지 다운로드 함수\n",
    "  # image_down_load.folder : 다운로드 폴더 만들기\n",
    "  # image_down_load.img : 이미지 다운로드 함수\n",
    "\n",
    "\n",
    "# url : 홈페이지 주소\n",
    "# page : 사용할 총 페이지 (하위페이지가 없을 경우 0을 입력)\n",
    "# name: 이미지를 저장할 폴더의 이름\n",
    "# class_source : soup한 정보 중 img가 담긴 class 이름 ex)\"gallery-asset__thumb gallery-mosaic-asset__thumb\"\n",
    "# img_source : class 내 img의 url이 담겨진 속성값 이름 ex) \"src\"\n",
    "# number : 저장할 이미지 순번(1씩 증가하여 저장)\n",
    "\n",
    "\"\"\"\n",
    "url =\n",
    "page = \n",
    "name = str()\n",
    "class_source = str()\n",
    "img_source = str()\n",
    "number = \n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "image_down_load(url, page, name, class_source, img_source, number) :\n",
    "\"\"\"\n",
    "class image_down_load :\n",
    "    \n",
    "    def __init__(self, url, page, name, class_source, img_source, number) :\n",
    "        self.name = name\n",
    "        self.page = int(page)\n",
    "        self.url = url\n",
    "        self.class_source = class_source\n",
    "        self.img_source = img_source\n",
    "        self.number = number\n",
    "        \n",
    "    def folder(self):\n",
    "        os.mkdir(self.name)\n",
    "\n",
    "    def img(self) : \n",
    "\n",
    "        #number의 int화\n",
    "        number = int(self.number)\n",
    "        \n",
    "        #저장 폴더 위치 정하기 \n",
    "        place = \"./\" + self.name + \"/\"\n",
    "\n",
    "        # 하위 페이지가 없는 경우\n",
    "        if number == 0:\n",
    "            #BeauifulSoup를 이용해서 URL에 담긴 정보 담아오기\n",
    "            with requests.get(self.url) as res:\n",
    "                soup = BeautifulSoup(res.text, 'html.parser')\n",
    "\n",
    "            #불러온 정보에서 원하는 이미지 class 내 정보찾기\n",
    "            inpo_class = soup.find_all(\"img\", class_=self.class_source)\n",
    "\n",
    "            #이미지 저장하기\n",
    "            #enumerate 함수에 자료형을 입력하면 인덱스와 값을 포함하는 enumerate(열거) 객체를 리턴 받는다\n",
    "            for i, link in enumerate(inpo_class):\n",
    "\n",
    "                #img 정보가 담긴 속성값 찾기\n",
    "                src = link.get(self.img_source)\n",
    "                print(\"number == 0\")\n",
    "\n",
    "                #이미지 다운로드하기 urllib.request.urlretrieve 함수 사용 (url, 파일위치 + 이름)\n",
    "                urllib.request.urlretrieve(src, place + \"{}.jpg\".format(number))\n",
    "\n",
    "        else : \n",
    "            for p in range(self.page + 1) : \n",
    "                new_url = self.url + \"&pagi={}\".format(p)\n",
    "                        #BeauifulSoup를 이용해서 URL에 담긴 정보 담아오기\n",
    "                with requests.get(new_url) as res:\n",
    "                    soup = BeautifulSoup(res.text, 'html.parser')\n",
    "\n",
    "                #불러온 정보에서 원하는 이미지 class 내 정보찾기\n",
    "            \n",
    "                inpo_class = soup.find_all(\"img\")\n",
    "\"\"\"                print(inpo_class)\n",
    "                #이미지 저장하기\n",
    "                #enumerate 함수에 자료형을 입력하면 인덱스와 값을 포함하는 enumerate(열거) 객체를 리턴 받는다\n",
    "                for i, link in enumerate(inpo_class):\n",
    "\n",
    "                    #img 정보가 담긴 속성값 찾기\n",
    "                    src = link.get(self.img_source)\n",
    "                    \n",
    "\n",
    "                    #이미지 다운로드하기 urllib.request.urlretrieve 함수 사용 (url, 파일위치 + 이름)\n",
    "                    urllib.request.urlretrieve(src, place + \"{}.jpg\".format(number))\n",
    "                    \n",
    "                    number += 1\n",
    "\"\"\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "liable-personality",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://pixabay.com/ko/images/search/dogs'\n",
    "page = 50\n",
    "name = \"dogs\"\n",
    "class_source = \"schema.org/ImageObject\"\n",
    "img_source = \"src\"\n",
    "number = 1\n",
    "\n",
    "down = image_down_load(url, page, name, class_source, img_source, number)\n",
    "#down.folder()\n",
    "down.img()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "secondary-alcohol",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "productive-quarterly",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "catholic-basement",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"C:/Users/thcho/my-git/study/studyfile/13주차_mini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acceptable-freedom",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib.request\n",
    "\n",
    "folderspot = \"./dogs/\"\n",
    "k = 1\n",
    "url = 'https://www.google.com/search?q=%EC%8B%9C%EB%B0%94%EA%B2%AC&hl=ko&sxsrf=ALeKk02rwXbcrE2Z1UibjYIaGUkLUg5PYw:1614323428886&source=lnms&tbm=isch&sa=X&ved=2ahUKEwiq2p-0_4bvAhUxE6YKHYynD3MQ_AUoAXoECAoQAw&biw=2053&bih=1024'\n",
    "with requests.get(url) as res:\n",
    "    soup = BeautifulSoup(res.text, 'html.parser')\n",
    "    for i in soup.find_all(\"img\"):\n",
    "        print(i.attrs[\"src\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "processed-professor",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib.request\n",
    "\n",
    "folderspot = \"./dogs/\"\n",
    "k = 1\n",
    "url = f'https://www.google.com/search?q={quote_plus(serch)}&sxsrf=ALeKk035ItLMK8j4bCZLqnPs9yQM7G__JA:1614325124007&source=lnms&tbm=isch&sa=X&ved=2ahUKEwiS2cXchYfvAhXTP3AKHd3VC-0Q_AUoAXoECBAQAw&biw=2053&bih=1024'\n",
    "with requests.get(url) as res:\n",
    "    soup = BeautifulSoup(res.text, 'html.parser')\n",
    "    print(len(soup.find_all(\"img\")))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "marine-encounter",
   "metadata": {},
   "outputs": [],
   "source": [
    "#구글 이미지 크롤링하기\n",
    " \n",
    "from urllib.request import urlopen\n",
    "from urllib.request import urlretrieve\n",
    "from urllib.parse import quote_plus\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "import time\n",
    "import os\n",
    "import urllib\n",
    "\n",
    "search = input(\"\")\n",
    "\n",
    "#search 폴더 생성하기\n",
    "os.mkdir(search)\n",
    "\n",
    "#폴더 위치 경로 생성하기\n",
    "place = \"./\" + search + \"/\"\n",
    "url  = f'https://www.google.com/search?q={quote_plus(search)}&sxsrf=ALeKk035ItLMK8j4bCZLqnPs9yQM7G__JA:1614325124007&source=lnms&tbm=isch&sa=X&ved=2ahUKEwiS2cXchYfvAhXTP3AKHd3VC-0Q_AUoAXoECBAQAw&biw=2053&bih=1024'\n",
    "\n",
    "# webdriver로 url 이용하여 Chrome 오픈하기\n",
    "driver = webdriver.Chrome()\n",
    "driver.get(url)\n",
    "\n",
    "# 결과 더 보기 버튼 누르기\n",
    "\n",
    "#스크롤 : 더 많은 사진 얻기위함\n",
    "\n",
    "last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "while True : \n",
    "    driver.execute_script(\"window.scrollTo(0,document.body.scrollHeight);\")\n",
    "    time.sleep(1)\n",
    "    new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "    if new_height == last_height :\n",
    "        try : \n",
    "            driver.find_element_by_css_selector(\".mye4qd\").click()\n",
    "            \n",
    "        except : \n",
    "            break\n",
    "            \n",
    "    last_heigh = new_height\n",
    "\n",
    "\n",
    "    # webdriver의 source 받아 image source 찾기\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html)\n",
    "    img = soup.select('.rg_i.Q4LuWd')\n",
    "    k = 1\n",
    "\n",
    "    imgurl = []\n",
    "\n",
    "\n",
    "    #src 찾아서 .jpg의 url 찾기\n",
    "    #이미지 다운로드    \n",
    "\n",
    "    for i in img :\n",
    "        try : \n",
    "            imgurl.append(i.attrs[\"src\"])\n",
    "            opener = urllib.request.build_opener()\n",
    "            opener.addheaders=[('User-Agent','Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/88.0.4324.182 Safari/537.36')]\n",
    "            urllib.request.install_opener(opener)\n",
    "\n",
    "         \n",
    "            for i in imgurl :\n",
    "                urlretrieve(i, place + search + \"_{}.jpg\".format(k))\n",
    "                k += 1\n",
    "\n",
    "        except KeyError : \n",
    "            imgurl.append(i.attrs[\"data-src\"])\n",
    "\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "delayed-dancing",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"            for i in imgurl :\n",
    "                urlretrieve(i, place + search + \"_{}.jpg\".format(k))\n",
    "                k += 1\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alive-segment",
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "from urllib.request import urlretrieve\n",
    "from urllib.parse import quote_plus\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "import time\n",
    "import os\n",
    "import urllib\n",
    "search = input(\"\")\n",
    "#search 폴더 생성하기\n",
    "os.mkdir(search)\n",
    "#폴더 위치 경로 생성하기\n",
    "place = \"./\" + search + \"/\"\n",
    "url  = f'https://www.google.com/search?q={quote_plus(search)}&sxsrf=ALeKk035ItLMK8j4bCZLqnPs9yQM7G__JA:1614325124007&source=lnms&tbm=isch&sa=X&ved=2ahUKEwiS2cXchYfvAhXTP3AKHd3VC-0Q_AUoAXoECBAQAw&biw=2053&bih=1024'\n",
    "# webdriver로 url 이용하여 Chrome 오픈하기\n",
    "driver = webdriver.Chrome()\n",
    "driver.get(url)\n",
    "# 결과 더 보기 버튼 누르기\n",
    "#스크롤 : 더 많은 사진 얻기위함\n",
    "#브라우저의 높이를 Javascript로 찾아서 last_height으로 설정해준다\n",
    "last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "while True :\n",
    "    #화면 가장 아래로 스크롤 내리기\n",
    "    driver.execute_script(\"window.scrollTo(0,document.body.scrollHeight);\")\n",
    "    \n",
    "    time.sleep(2)\n",
    "    \n",
    "    #현재 문서를 가져와서 저장 \n",
    "    new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "\n",
    "    # webdriver의 source 받아 image source 찾기\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html)\n",
    "    img = soup.select('.rg_i.Q4LuWd')\n",
    "    k = 1\n",
    "    imgurl = []\n",
    "    #src 찾아서 .jpg의 url 찾기\n",
    "    #이미지 다운로드\n",
    "    for i in img :\n",
    "        try :\n",
    "            imgurl.append(i.attrs[\"src\"])\n",
    "            opener = urllib.request.build_opener()\n",
    "            opener.addheaders=[('User-Agent','Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/88.0.4324.182 Safari/537.36')]\n",
    "            urllib.request.install_opener(opener)\n",
    "            print(src)\n",
    "\n",
    "        except KeyError :\n",
    "            imgurl.append(i.attrs[\"data-src\"])\n",
    "            \n",
    "    if new_height == last_height :\n",
    "        try :\n",
    "            driver.find_element_by_css_selector(\".mye4qd\").click()\n",
    "        except :\n",
    "            break\n",
    "    last_heigh = new_height\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "future-durham",
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "from urllib.request import urlretrieve\n",
    "from urllib.parse import quote_plus\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "import time\n",
    "import os\n",
    "import urllib\n",
    "search = input(\"\")\n",
    "#search 폴더 생성하기\n",
    "os.mkdir(search)\n",
    "#폴더 위치 경로 생성하기\n",
    "place = \"./\" + search + \"/\"\n",
    "url  = f'https://www.google.com/search?q={quote_plus(search)}&sxsrf=ALeKk035ItLMK8j4bCZLqnPs9yQM7G__JA:1614325124007&source=lnms&tbm=isch&sa=X&ved=2ahUKEwiS2cXchYfvAhXTP3AKHd3VC-0Q_AUoAXoECBAQAw&biw=2053&bih=1024'\n",
    "# webdriver로 url 이용하여 Chrome 오픈하기\n",
    "driver = webdriver.Chrome()\n",
    "driver.get(url)\n",
    "# 결과 더 보기 버튼 누르기\n",
    "#스크롤 : 더 많은 사진 얻기위함\n",
    "#브라우저의 높이를 Javascript로 찾아서 last_height으로 설정해준다\n",
    "last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "while True :\n",
    "    #화면 가장 아래로 스크롤 내리기\n",
    "    driver.execute_script(\"window.scrollTo(0,document.body.scrollHeight);\")\n",
    "    \n",
    "    time.sleep(2)\n",
    "    \n",
    "    #현재 문서를 가져와서 저장 \n",
    "    new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "\n",
    "    # webdriver의 source 받아 image source 찾기\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html)\n",
    "    img = soup.select('.rg_i.Q4LuWd')\n",
    "    k = 1\n",
    "    imgurl = []\n",
    "    #src 찾아서 .jpg의 url 찾기\n",
    "    #이미지 다운로드\n",
    "    for i in img :\n",
    "        try :\n",
    "            imgurl.append(i.attrs[\"src\"])\n",
    "            opener = urllib.request.build_opener()\n",
    "            opener.addheaders=[('User-Agent','Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/88.0.4324.182 Safari/537.36')]\n",
    "            urllib.request.install_opener(opener)\n",
    "            print(src)\n",
    "\n",
    "        except KeyError :\n",
    "            imgurl.append(i.attrs[\"data-src\"])\n",
    "            \n",
    "    if new_height == last_height :\n",
    "        try :\n",
    "            driver.find_element_by_css_selector(\".mye4qd\").click()\n",
    "        except :\n",
    "            break\n",
    "    last_heigh = new_height\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "passive-ghost",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 검색까지 완료\n",
    "\n",
    "from urllib.request import urlopen\n",
    "from urllib.request import urlretrieve\n",
    "from urllib.parse import quote_plus\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "import time\n",
    "import os\n",
    "import urllib\n",
    "search = input(\"\")\n",
    "#search 폴더 생성하기\n",
    "#os.mkdir(search)\n",
    "#폴더 위치 경로 생성하기\n",
    "place = \"./\" + search + \"/\"\n",
    "url  = f'https://www.google.com/search?q={quote_plus(search)}&sxsrf=ALeKk035ItLMK8j4bCZLqnPs9yQM7G__JA:1614325124007&source=lnms&tbm=isch&sa=X&ved=2ahUKEwiS2cXchYfvAhXTP3AKHd3VC-0Q_AUoAXoECBAQAw&biw=2053&bih=1024'\n",
    "# webdriver로 url 이용하여 Chrome 오픈하기\n",
    "driver = webdriver.Chrome()\n",
    "driver.get(url)\n",
    "# 결과 더 보기 버튼 누르기\n",
    "#스크롤 : 더 많은 사진 얻기위함\n",
    "\n",
    "#브라우저의 높이를 Javascript로 찾아서 last_height으로 설정해준다\n",
    "last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "while True :\n",
    "    #화면 가장 아래로 스크롤 내리기\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    time.sleep(1)\n",
    "    new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "\n",
    "    if new_height == last_height :\n",
    "        try : \n",
    "            driver.find_element_by_css_selector(\".mye4qd\").click()\n",
    "        except : \n",
    "            break\n",
    "    last_height = new_height\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dated-armor",
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "from urllib.request import urlretrieve\n",
    "from urllib.parse import quote_plus\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "import os\n",
    "import urllib\n",
    "search = input(\"\")\n",
    "#search 폴더 생성하기\n",
    "#os.mkdir(search)\n",
    "#폴더 위치 경로 생성하기\n",
    "place = \"./\" + search + \"/\"\n",
    "url  = f'https://www.google.com/search?q={quote_plus(search)}&sxsrf=ALeKk035ItLMK8j4bCZLqnPs9yQM7G__JA:1614325124007&source=lnms&tbm=isch&sa=X&ved=2ahUKEwiS2cXchYfvAhXTP3AKHd3VC-0Q_AUoAXoECBAQAw&biw=2053&bih=1024'\n",
    "# webdriver로 url 이용하여 Chrome 오픈하기\n",
    "driver = webdriver.Chrome()\n",
    "driver.get(url)\n",
    "# 결과 더 보기 버튼 누르기\n",
    "#스크롤 : 더 많은 사진 얻기위함\n",
    "\n",
    "#브라우저의 높이를 Javascript로 찾아서 last_height으로 설정해준다\n",
    "last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "while True :\n",
    "    #화면 가장 아래로 스크롤 내리기\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    time.sleep(1)\n",
    "    new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "\n",
    "    if new_height == last_height :\n",
    "        try : \n",
    "            driver.find_element_by_css_selector(\".mye4qd\").click()\n",
    "        except : \n",
    "            break\n",
    "    last_height = new_height\n",
    "\n",
    "\n",
    "# webdriver의 source 받아 image source 찾기\n",
    "imgs = driver.find_elements_by_css_selector('.rg_i.Q4LuWd')\n",
    "k = 1\n",
    "\n",
    " \n",
    "#src 찾아서 .jpg의 url 찾기\n",
    "#이미지 다운로드    \n",
    "\n",
    "for img in imgs :\n",
    "        img.click()\n",
    "        time.sleep(1)\n",
    "        imgurl = driver.find_element_by_xpath(\"/html/body/div[2]/c-wiz/div[3]/div[2]/div[3]/div/div/div[3]/div[2]/c-wiz/div/div[1]/div[1]/div/div[2]/a/img\").get_attribute(\"src\")\n",
    "    \n",
    "        opener = urllib.request.build_opener()\n",
    "        opener.addheaders=[('User-Agent','Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/88.0.4324.182 Safari/537.36')]\n",
    "        urllib.request.install_opener(opener)\n",
    "        print(imgurl)\n",
    "        time.sleep(1)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "posted-marine",
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "from urllib.request import urlretrieve\n",
    "from urllib.parse import quote_plus\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "import os\n",
    "import urllib\n",
    "search = input(\"\")\n",
    "#search 폴더 생성하기\n",
    "#os.mkdir(search)\n",
    "#폴더 위치 경로 생성하기\n",
    "place = \"./\" + search + \"/\"\n",
    "url  = f'https://www.google.com/search?q={quote_plus(search)}&sxsrf=ALeKk035ItLMK8j4bCZLqnPs9yQM7G__JA:1614325124007&source=lnms&tbm=isch&sa=X&ved=2ahUKEwiS2cXchYfvAhXTP3AKHd3VC-0Q_AUoAXoECBAQAw&biw=2053&bih=1024'\n",
    "# webdriver로 url 이용하여 Chrome 오픈하기\n",
    "driver = webdriver.Chrome()\n",
    "driver.get(url)\n",
    "# 결과 더 보기 버튼 누르기\n",
    "#스크롤 : 더 많은 사진 얻기위함\n",
    "\n",
    "#브라우저의 높이를 Javascript로 찾아서 last_height으로 설정해준다\n",
    "last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "while True :\n",
    "    #화면 가장 아래로 스크롤 내리기\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    time.sleep(1)\n",
    "    new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "\n",
    "    if new_height == last_height :\n",
    "        try : \n",
    "            driver.find_element_by_css_selector(\".mye4qd\").click()\n",
    "        except : \n",
    "            break\n",
    "    last_height = new_height\n",
    "\n",
    "\n",
    "# webdriver의 source 받아 image source 찾기\n",
    "imgs = driver.find_elements_by_css_selector('.rg_i.Q4LuWd')\n",
    "k = 1\n",
    "\n",
    " \n",
    "#src 찾아서 .jpg의 url 찾기\n",
    "#이미지 다운로드    \n",
    "\n",
    "for img in imgs :\n",
    "    try : \n",
    "        \n",
    "        #img.click() 사용시 Clicks the element라는 오류 발생. \n",
    "        img.click()\n",
    "        time.sleep(3)\n",
    "        imgurl = driver.find_element_by_xpath(\"/html/body/div[2]/c-wiz/div[3]/div[2]/div[3]/div/div/div[3]/div[2]/c-wiz/div/div[1]/div[1]/div/div[2]/a/img\").get_attribute(\"src\")\n",
    "    \n",
    "        opener = urllib.request.build_opener()\n",
    "        opener.addheaders=[('User-Agent','Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/88.0.4324.182 Safari/537.36')]\n",
    "        urllib.request.install_opener(opener)\n",
    "        urllib.request.urlretrieve(imgurl, place + search + \"_{}.jpg\".format(k))\n",
    "        k += 1\n",
    "\n",
    "    except KeyError : \n",
    "        imgurl.append(i.attrs[\"data-src\"])\n",
    "        \n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "severe-orientation",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Hello World\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "least-contamination",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chrome \n",
    "from urllib.request import urlopen\n",
    "from urllib.request import urlretrieve\n",
    "from urllib.parse import quote_plus\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "import time\n",
    "import os\n",
    "import urllib\n",
    "search = input(\"\")\n",
    "#search 폴더 생성하기\n",
    "os.mkdir(search)\n",
    "#폴더 위치 경로 생성하기\n",
    "place = \"./\" + search + \"/\"\n",
    "url  = f'https://www.google.com/search?q={quote_plus(search)}&sxsrf=ALeKk035ItLMK8j4bCZLqnPs9yQM7G__JA:1614325124007&source=lnms&tbm=isch&sa=X&ved=2ahUKEwiS2cXchYfvAhXTP3AKHd3VC-0Q_AUoAXoECBAQAw&biw=2053&bih=1024'\n",
    "# webdriver로 url 이용하여 Chrome 오픈하기\n",
    "driver = webdriver.Chrome()\n",
    "driver.get(url)\n",
    "# 결과 더 보기 버튼 누르기\n",
    "#스크롤 : 더 많은 사진 얻기위함\n",
    "\n",
    "#브라우저의 높이를 Javascript로 찾아서 last_height으로 설정해준다\n",
    "last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "while True :\n",
    "    #화면 가장 아래로 스크롤 내리기\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    time.sleep(1)\n",
    "    new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "\n",
    "    if new_height == last_height :\n",
    "        try : \n",
    "            driver.find_element_by_css_selector(\".mye4qd\").click()\n",
    "        except : \n",
    "            break\n",
    "    last_height = new_height\n",
    "\n",
    "\n",
    "# webdriver의 source 받아 image source 찾기\n",
    "html = driver.page_source\n",
    "soup = BeautifulSoup(html)\n",
    "img = soup.select(\".rg_i.Q4LuWd\")\n",
    "driver.close()\n",
    "k = 1\n",
    "for im in img : \n",
    "    try : \n",
    "        down_img_url = im.attrs[\"src\"]\n",
    "        urllib.request.urlretrieve(down_img_url, place + \"{}.jpg\".format(k))\n",
    "        k +=1\n",
    "        \n",
    "    except : \n",
    "        down_img_url = im.attrs[\"data-src\"]\n",
    "        urllib.request.urlretrieve(down_img_url, place + \"{}.jpg\".format(k))\n",
    "        k +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "responsible-radical",
   "metadata": {},
   "outputs": [],
   "source": [
    "#naver \n",
    "\n",
    "from urllib.request import urlopen\n",
    "from urllib.request import urlretrieve\n",
    "from urllib.parse import quote_plus\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "import time\n",
    "import os\n",
    "import urllib\n",
    "search = input(\"\")\n",
    "#search 폴더 생성하기\n",
    "os.mkdir(search)\n",
    "#폴더 위치 경로 생성하기\n",
    "place = \"./\" + search + \"/\"\n",
    "url  = f'https://search.naver.com/search.naver?where=image&sm=tab_jum&query={quote_plus(search)}'\n",
    "# webdriver로 url 이용하여 Chrome 오픈하기\n",
    "driver = webdriver.Chrome()\n",
    "driver.get(url)\n",
    "# 결과 더 보기 버튼 누르기\n",
    "#스크롤 : 더 많은 사진 얻기위함\n",
    "\n",
    "#브라우저의 높이를 Javascript로 찾아서 last_height으로 설정해준다\n",
    "last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "while True :\n",
    "    #화면 가장 아래로 스크롤 내리기\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    time.sleep(1)\n",
    "    new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "\n",
    "    if new_height == last_height :\n",
    "        try : \n",
    "            driver.find_element_by_css_selector(\".mye4qd\").click()\n",
    "        except : \n",
    "            break\n",
    "    last_height = new_height\n",
    "    \n",
    "\n",
    "# webdriver의 source 받아 image source 찾기\n",
    "html = driver.page_source\n",
    "soup = BeautifulSoup(html)\n",
    "print(type(soup))\n",
    "img = soup.find_all(\"img\", class_=\"_image _listImage\")\n",
    "k = 1\n",
    "driver.close()\n",
    "for im in img :\n",
    "    down_img_url = im.attrs[\"src\"]\n",
    "    if down_img_url == \"data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7\":\n",
    "        down_img_url = im.attrs[\"data-lazy-src\"]\n",
    "    urllib.request.urlretrieve(down_img_url, place + \"{}.jpg\".format(k))\n",
    "    k +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "advanced-revelation",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'bs4'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-0c19f9265086>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0murllib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0murlretrieve\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0murllib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mquote_plus\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mbs4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mselenium\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mwebdriver\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'bs4'"
     ]
    }
   ],
   "source": [
    "#instagram \n",
    "\n",
    "from urllib.request import urlopen\n",
    "from urllib.request import urlretrieve\n",
    "from urllib.parse import quote_plus\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "import time\n",
    "import os\n",
    "import urllib\n",
    "search = input(\"\")\n",
    "#search 폴더 생성하기\n",
    "os.mkdir(search)\n",
    "#폴더 위치 경로 생성하기\n",
    "place = \"./\" + search + \"/\"\n",
    "url  = f'https://www.instagram.com/explore/tags/{quote_plus(search)}/'\n",
    "# webdriver로 url 이용하여 instagram 오픈하기\n",
    "driver = webdriver.Chrome()\n",
    "driver.get(url)\n",
    "# 결과 더 보기 버튼 누르기\n",
    "#스크롤 : 더 많은 사진 얻기위함\n",
    "\n",
    "#브라우저의 높이를 Javascript로 찾아서 last_height으로 설정해준다\n",
    "last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "while True :\n",
    "    #화면 가장 아래로 스크롤 내리기\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    time.sleep(1)\n",
    "    new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "    last_height = new_height\n",
    "    \n",
    "\n",
    "# webdriver의 source 받아 image source 찾기\n",
    "html = driver.page_source\n",
    "soup = BeautifulSoup(html)\n",
    "print(type(soup))\n",
    "img = soup.find_all(\"img\", class_=\"FFVAD\")\n",
    "k = 1\n",
    "driver.close()\n",
    "print(img)\n",
    "\"\"\"\n",
    "for im in img :\n",
    "    down_img_url = im.attrs[\"src\"]\n",
    "    if down_img_url == \"data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7\":\n",
    "        down_img_url = im.attrs[\"data-lazy-src\"]\n",
    "    urllib.request.urlretrieve(down_img_url, place + \"{}.jpg\".format(k))\n",
    "    k +=1\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pressing-insurance",
   "metadata": {},
   "outputs": [],
   "source": [
    "for im in img :\n",
    "    down_img_url = im.attrs[\"src\"]\n",
    "    if down_img_url != \"data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7\":\n",
    "        print(down_img_url)\n",
    "    else : \n",
    "        down_img_url = im.attrs[\"data-lazy-src\"]\n",
    "        print(down_img_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "australian-grocery",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "img = cv2.imread('시츄/2.jpg')\n",
    "type(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "declared-navigation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aerial-browse",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sonic-fabric",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "level-challenge",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('시츄 (1).jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "clean-bible",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "serial-pickup",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "# With jupyter notebook uncomment below line\n",
    "# %matplotlib inline\n",
    "# This plots figures inside the notebook\n",
    "img = cv2.imread('sichu/sichu (1).jpg')\n",
    "print(type(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wireless-graduate",
   "metadata": {},
   "outputs": [],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unable-parking",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "img = cv2.imread('sichu/sichu (1).jpg')\n",
    "\n",
    "def plot_cv_img(input_image):\n",
    "    \"\"\"\n",
    "    Converts an image from BGR to RGB and plots\n",
    "    \"\"\"\n",
    "    # change color channels order for matplotlib\n",
    "    plt.imshow(cv2.cvtColor(input_image, cv2.COLOR_BGR2RGB))\n",
    "    # For easier view, turn off axis around image\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    # 이미지는 array로 되어 있기 때문에, 배열 슬라이싱을 사용하여 자를 수 있다.\n",
    "plot_cv_img(img) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "foreign-spine",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('sichu/sichu (1).jpg')\n",
    "\n",
    "def plot_gray(input_image, output_image):\n",
    "    \"\"\"\n",
    "    Converts an image from BGR to RGB and plots\n",
    "    \"\"\"\n",
    "    # change color channels order for matplotlib\n",
    "    fig, ax = plt.subplots(nrows=1, ncols=2)\n",
    "    ax[0].imshow(input_image, cmap='gray')\n",
    "    ax[0].set_title('Input Image')\n",
    "    ax[0].axis('off')\n",
    "\n",
    "    ax[1].imshow(output_image, cmap='gray')\n",
    "    ax[1].set_title('Histogram Equalized ')\n",
    "    ax[1].axis('off')\n",
    "\n",
    "    plt.show()\n",
    "def main():\n",
    "    # read an image\n",
    "    img = cv2.imread('sichu/sichu (1).jpg')\n",
    "\n",
    "    # grayscale image is used for equalization\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # following function performs equalization on input image\n",
    "    equ = cv2.equalizeHist(gray)\n",
    "\n",
    "    # for visualizing input and output side by side\n",
    "    plot_gray(gray, equ)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "parliamentary-failure",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "# sobel\n",
    "x_sobel = cv2.Sobel(img,cv2.CV_64F,1,0,ksize=5)\n",
    "y_sobel = cv2.Sobel(img,cv2.CV_64F,0,1,ksize=5)\n",
    "# laplacian\n",
    "lapl = cv2.Laplacian(img,cv2.CV_64F, ksize=5)\n",
    "# gaussian blur\n",
    "blur = cv2.GaussianBlur(img,(5,5),0)\n",
    "# laplacian of gaussian\n",
    "log = cv2.Laplacian(blur,cv2.CV_64F, ksize=5) # 가우시안 + 라플라시안\n",
    "def plot_show_img(input_image, output_image1, output_image2, output_image3):\n",
    "    \"\"\"\n",
    "    Converts an image from BGR to RGB and plots\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(nrows=1, ncols=4)\n",
    "    ax[0].imshow(input_image)\n",
    "    ax[0].set_title('Input Image')\n",
    "    ax[0].axis('off')\n",
    "\n",
    "    ax[1].imshow(output_image1)\n",
    "    ax[1].set_title('one_Image')\n",
    "    ax[1].axis('off')\n",
    "    ax[2].imshow(output_image2)\n",
    "    ax[2].set_title('two_Image')\n",
    "    ax[2].axis('off')\n",
    "    ax[3].imshow(output_image3)\n",
    "    ax[3].set_title('three_Image')\n",
    "    ax[3].axis('off')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "plot_show_img(img, lapl, blur, log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "certified-oracle",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "img = cv2.imread('sichu/sichu (1).jpg')\n",
    "\n",
    "def plot_cv_img(input_image):\n",
    "    \"\"\"\n",
    "    Converts an image from BGR to RGB and plots\n",
    "    \"\"\"\n",
    "    # change color channels order for matplotlib\n",
    "    plt.imshow(input_image, cmap = 'gray')\n",
    "    # For easier view, turn off axis around image\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    # 이미지는 array로 되어 있기 때문에, 배열 슬라이싱을 사용하여 자를 수 있다.\n",
    "\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "plot_cv_img(gray) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intense-industry",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "img = cv2.imread('sichu/sichu (1).jpg')\n",
    "\n",
    "def plot_cv_img(input_image):\n",
    "    \"\"\"\n",
    "    Converts an image from BGR to RGB and plots\n",
    "    \"\"\"\n",
    "    # change color channels order for matplotlib\n",
    "    plt.imshow(input_image, cmap = 'gray')\n",
    "    # For easier view, turn off axis around image\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    # 이미지는 array로 되어 있기 때문에, 배열 슬라이싱을 사용하여 자를 수 있다.\n",
    "\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "\n",
    "# sobel\n",
    "x_sobel = cv2.Sobel(gray,cv2.CV_64F,1,0,ksize=5)\n",
    "y_sobel = cv2.Sobel(gray,cv2.CV_64F,0,1,ksize=5)\n",
    "# laplacian\n",
    "lapl = cv2.Laplacian(gray,cv2.CV_64F, ksize=5)\n",
    "# gaussian blur\n",
    "blur = cv2.GaussianBlur(gray,(5,5),0)\n",
    "# laplacian of gaussian\n",
    "log = cv2.Laplacian(blur,cv2.CV_64F, ksize=5) # 가우시안 + 라플라시안\n",
    "def plot_show_img(input_image, output_image1, output_image2, output_image3):\n",
    "    \"\"\"\n",
    "    Converts an image from BGR to RGB and plots\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(nrows=1, ncols=4)\n",
    "    ax[0].imshow(input_image, cmap = 'gray')\n",
    "    ax[0].set_title('Input Image')\n",
    "    ax[0].axis('off')\n",
    "\n",
    "    ax[1].imshow(output_image1, cmap = 'gray')\n",
    "    ax[1].set_title('one_Image')\n",
    "    ax[1].axis('off')\n",
    "    ax[2].imshow(output_image2, cmap = 'gray')\n",
    "    ax[2].set_title('two_Image')\n",
    "    ax[2].axis('off')\n",
    "    ax[3].imshow(output_image3, cmap = 'gray')\n",
    "    ax[3].set_title('three_Image')\n",
    "    ax[3].axis('off')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "plot_show_img(gray, lapl, blur, log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "touched-title",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "img = cv2.imread('sichu/sichu (1).jpg')\n",
    "blur = cv2.GaussianBlur(gray,(5,5),0)\n",
    "lapl = cv2.Laplacian(gray,cv2.CV_64F, ksize=5)\n",
    "\n",
    "log = cv2.Laplacian(blur,cv2.CV_64F, ksize=5) # 가우시안 + 라플라시안\n",
    "plt.imshow(lapl, cmap = 'gray')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "encouraging-herald",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "img = cv2.imread('sichu/sichu (1).jpg')\n",
    "blur = cv2.GaussianBlur(gray,(5,5),0)\n",
    "\n",
    "blur = blur / 255\n",
    "\n",
    "log = cv2.Laplacian(blur,cv2.CV_64F, ksize=5) # 가우시안 + 라플라시안\n",
    "plt.imshow(log, cmap = 'gray')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "diverse-cutting",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "import sys\n",
    "import urllib.request\n",
    "from PyQt5.QtWidgets import *\n",
    "from PyQt5.QtCore import *\n",
    "from PyQt5.QtGui import *\n",
    "from PyQt5 import uic\n",
    "from glob import glob\n",
    "import os \n",
    "\n",
    "form_class = uic.loadUiType(\"pixmapTest.ui\")[0]\n",
    "picture_path = \"사진분류용/PetFinder_All/Adult/\"\n",
    "images = os.listdir(picture_path)\n",
    "\n",
    "try :\n",
    "    os.mkdir(\"./select\")\n",
    "except FileExistsError:\n",
    "    pass \n",
    "\n",
    "class WindowClass(QMainWindow, form_class , QWidget) :\n",
    "   \n",
    "    def __init__(self) :\n",
    "        super().__init__()\n",
    "        self.setupUi(self)\n",
    "        self.image_idx = 0 \n",
    "\n",
    "    def keyPressEvent(self , e):\n",
    "         \n",
    "        if e.key()==Qt.Key_S:\n",
    "            self.qPixmapSaveVar = self.lbl_picture.pixmap()\n",
    "            self.qPixmapSaveVar.save(\"./select/\"+images[self.image_idx-1])\n",
    "        elif e.key()==Qt.Key_L:\n",
    "            self.qPixmapFileVar = QPixmap()\n",
    "            self.qPixmapFileVar.load(os.path.join(picture_path,images[self.image_idx]))\n",
    "            self.qPixmapFileVar = self.qPixmapFileVar.scaledToWidth(600)\n",
    "            self.lbl_picture.setPixmap(self.qPixmapFileVar)\n",
    "            self.image_idx += 1 \n",
    "        elif e.key()==Qt.Key_J:\n",
    "            self.qPixmapFileVar = QPixmap()\n",
    "            self.qPixmapFileVar.load(os.path.join(picture_path,images[self.image_idx]))\n",
    "            self.qPixmapFileVar = self.qPixmapFileVar.scaledToWidth(600)\n",
    "            self.lbl_picture.setPixmap(self.qPixmapFileVar)\n",
    "            self.image_idx -= 1\n",
    "        \n",
    "        else :\n",
    "            pass\n",
    "        \n",
    "\n",
    "if __name__ == \"__main__\" :\n",
    "    app = QApplication(sys.argv)\n",
    "    myWindow = WindowClass()\n",
    "    myWindow.show()\n",
    "    app.exec_() \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "short-weight",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 개 나이 대 분류\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout, Flatten, Dense, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import optimizers, initializers, regularizers, metrics\n",
    "\n",
    "\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu',\n",
    "                        input_shape=(150, 150, 3)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Flatten())\n",
    "\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(layers.Dense(512, activation='relu'))\n",
    "model.add(layers.Dense(3, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "descending-productivity",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "danish-relevance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 열기\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout, Flatten, Dense, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import optimizers, initializers, regularizers, metrics\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "valid_dir = \"dataset_age/dataset_age/valid\"\n",
    "train_dir = \"dataset_age/dataset_age/train\"\n",
    "\n",
    "\n",
    "# 모든 이미지를 1/255로 스케일을 조정합니다\n",
    "valid_datagen = ImageDataGenerator(rescale=1./255)\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        # 타깃 디렉터리\n",
    "        train_dir,\n",
    "        # 모든 이미지를 150 × 150 크기로 바꿉니다\n",
    "        target_size=(150, 150),\n",
    "        batch_size=20,\n",
    "        # binary_crossentropy 손실을 사용하기 때문에 이진 레이블이 필요합니다\n",
    "        class_mode='categorical')\n",
    "\n",
    "validation_generator = valid_datagen.flow_from_directory(\n",
    "        valid_dir,\n",
    "        target_size=(150, 150),\n",
    "        batch_size=20,\n",
    "        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "third-cause",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "train_dir_data = cv2.imread(\"dataset_age/dataset_age/train/8398260_1.jpg\")\n",
    "train_dir_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alleged-timber",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#모델을 실행합니다\n",
    "history = model.fit(# fit_generator에서 fit으로 통합됨.\n",
    "       train_generator,\n",
    "       steps_per_epoch=len(train_generator), #원래 이미지의 개수를 초과하지 않게 변경됨\n",
    "       epochs=100,   #적절한 값으로 조절합니다.\n",
    "       validation_data=validation_generator,\n",
    "       validation_steps=len(validation_generator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "metallic-cattle",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# 테스트 셋의 오차\n",
    "y_vloss = history.history['val_loss']\n",
    "\n",
    "# 학습셋의 오차\n",
    "y_loss = history.history['loss']\n",
    "\n",
    "# 그래프로 표현\n",
    "x_len = np.arange(len(y_loss))\n",
    "plt.plot(x_len, y_vloss, marker='.', c=\"red\", label='validset_loss')\n",
    "plt.plot(x_len, y_loss, marker='.', c=\"blue\", label='Trainset_loss')\n",
    "\n",
    "# 그래프에 그리드를 주고 레이블을 표시\n",
    "plt.legend(loc='upper right')\n",
    "plt.grid()\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "earlier-bahamas",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('first_model.h5')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "monetary-swaziland",
   "metadata": {},
   "source": [
    "# 개 데이터 확인하기\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abandoned-singer",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "# With jupyter notebook uncomment below line\n",
    "# %matplotlib inline\n",
    "# This plots figures inside the notebook\n",
    "img = cv2.imread('dataset_breed/dataset_breed/train/beagle/1.jpg')\n",
    "print(type(img))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pleasant-cruise",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(img), len(img[0]), len(img[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dental-enforcement",
   "metadata": {},
   "outputs": [],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dominant-applicant",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "def plot_cv_img(input_image):\n",
    " \"\"\"\n",
    " Converts an image from BGR to RGB and plots\n",
    " \"\"\"\n",
    " # change color channels order for matplotlib\n",
    " plt.imshow(cv2.cvtColor(input_image, cv2.COLOR_BGR2RGB))\n",
    " # For easier view, turn off axis around image\n",
    " plt.axis('off')\n",
    " plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abroad-booth",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cv_img(img[:299, :299]) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "surprising-raise",
   "metadata": {},
   "source": [
    "## 개의 종 분류하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "gorgeous-plaintiff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4443 images belonging to 8 classes.\n",
      "Found 1115 images belonging to 8 classes.\n"
     ]
    }
   ],
   "source": [
    "# 개 나이 대 분류\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout, Flatten, Dense, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import optimizers, initializers, regularizers, metrics\n",
    "\n",
    "\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu',\n",
    "                        input_shape=(299, 299, 3)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "#model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "#model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Flatten())\n",
    "\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(layers.Dense(512, activation='relu'))\n",
    "model.add(layers.Dense(8, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])\n",
    "\n",
    "# 이미지 열기\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout, Flatten, Dense, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import optimizers, initializers, regularizers, metrics\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "valid_dir = \"dataset_breed/dataset_breed/valid\"\n",
    "train_dir = \"dataset_breed/dataset_breed/train\"\n",
    "\n",
    "\n",
    "# 모든 이미지를 1/255로 스케일을 조정합니다\n",
    "valid_datagen = ImageDataGenerator(rescale=1./255)\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        # 타깃 디렉터리\n",
    "        train_dir,\n",
    "        # 모든 이미지를 150 × 150 크기로 바꿉니다\n",
    "        target_size=(299, 299),\n",
    "        batch_size=20,\n",
    "        # binary_crossentropy 손실을 사용하기 때문에 이진 레이블이 필요합니다\n",
    "        class_mode='categorical')\n",
    "\n",
    "validation_generator = valid_datagen.flow_from_directory(\n",
    "        valid_dir,\n",
    "        target_size=(299, 299),\n",
    "        batch_size=20,\n",
    "        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affiliated-savannah",
   "metadata": {},
   "outputs": [],
   "source": [
    "#모델을 실행합니다\n",
    "history = model.fit(# fit_generator에서 fit으로 통합됨.\n",
    "       train_generator,\n",
    "       steps_per_epoch=len(train_generator), #원래 이미지의 개수를 초과하지 않게 변경됨\n",
    "       epochs=100,   #적절한 값으로 조절합니다.\n",
    "       validation_data=validation_generator,\n",
    "       validation_steps=len(validation_generator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seventh-livestock",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# 테스트 셋의 오차\n",
    "y_vloss = history.history['val_loss']\n",
    "\n",
    "# 학습셋의 오차\n",
    "y_loss = history.history['loss']\n",
    "\n",
    "# 그래프로 표현\n",
    "x_len = np.arange(len(y_loss))\n",
    "plt.plot(x_len, y_vloss, marker='.', c=\"red\", label='validset_loss')\n",
    "plt.plot(x_len, y_loss, marker='.', c=\"blue\", label='Trainset_loss')\n",
    "\n",
    "# 그래프에 그리드를 주고 레이블을 표시\n",
    "plt.legend(loc='upper right')\n",
    "plt.grid()\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "social-acceptance",
   "metadata": {},
   "source": [
    "# Xception 이용해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "competitive-tuning",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.xception import Xception\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "closed-roads",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"xception\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 299, 299, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1 (Conv2D)           (None, 149, 149, 32) 864         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1_bn (BatchNormaliza (None, 149, 149, 32) 128         block1_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1_act (Activation)   (None, 149, 149, 32) 0           block1_conv1_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2 (Conv2D)           (None, 147, 147, 64) 18432       block1_conv1_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2_bn (BatchNormaliza (None, 147, 147, 64) 256         block1_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2_act (Activation)   (None, 147, 147, 64) 0           block1_conv2_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv1 (SeparableConv2 (None, 147, 147, 128 8768        block1_conv2_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv1_bn (BatchNormal (None, 147, 147, 128 512         block2_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2_act (Activation (None, 147, 147, 128 0           block2_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2 (SeparableConv2 (None, 147, 147, 128 17536       block2_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2_bn (BatchNormal (None, 147, 147, 128 512         block2_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 74, 74, 128)  8192        block1_conv2_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)      (None, 74, 74, 128)  0           block2_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 74, 74, 128)  512         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 74, 74, 128)  0           block2_pool[0][0]                \n",
      "                                                                 batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1_act (Activation (None, 74, 74, 128)  0           add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1 (SeparableConv2 (None, 74, 74, 256)  33920       block3_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1_bn (BatchNormal (None, 74, 74, 256)  1024        block3_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2_act (Activation (None, 74, 74, 256)  0           block3_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2 (SeparableConv2 (None, 74, 74, 256)  67840       block3_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2_bn (BatchNormal (None, 74, 74, 256)  1024        block3_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 37, 37, 256)  32768       add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)      (None, 37, 37, 256)  0           block3_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 37, 37, 256)  1024        conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 37, 37, 256)  0           block3_pool[0][0]                \n",
      "                                                                 batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1_act (Activation (None, 37, 37, 256)  0           add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1 (SeparableConv2 (None, 37, 37, 728)  188672      block4_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1_bn (BatchNormal (None, 37, 37, 728)  2912        block4_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2_act (Activation (None, 37, 37, 728)  0           block4_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2 (SeparableConv2 (None, 37, 37, 728)  536536      block4_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2_bn (BatchNormal (None, 37, 37, 728)  2912        block4_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 19, 19, 728)  186368      add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)      (None, 19, 19, 728)  0           block4_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 19, 19, 728)  2912        conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 19, 19, 728)  0           block4_pool[0][0]                \n",
      "                                                                 batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1_act (Activation (None, 19, 19, 728)  0           add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1 (SeparableConv2 (None, 19, 19, 728)  536536      block5_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1_bn (BatchNormal (None, 19, 19, 728)  2912        block5_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2_act (Activation (None, 19, 19, 728)  0           block5_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2 (SeparableConv2 (None, 19, 19, 728)  536536      block5_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2_bn (BatchNormal (None, 19, 19, 728)  2912        block5_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3_act (Activation (None, 19, 19, 728)  0           block5_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3 (SeparableConv2 (None, 19, 19, 728)  536536      block5_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3_bn (BatchNormal (None, 19, 19, 728)  2912        block5_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 19, 19, 728)  0           block5_sepconv3_bn[0][0]         \n",
      "                                                                 add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1_act (Activation (None, 19, 19, 728)  0           add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1 (SeparableConv2 (None, 19, 19, 728)  536536      block6_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1_bn (BatchNormal (None, 19, 19, 728)  2912        block6_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2_act (Activation (None, 19, 19, 728)  0           block6_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2 (SeparableConv2 (None, 19, 19, 728)  536536      block6_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2_bn (BatchNormal (None, 19, 19, 728)  2912        block6_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3_act (Activation (None, 19, 19, 728)  0           block6_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3 (SeparableConv2 (None, 19, 19, 728)  536536      block6_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3_bn (BatchNormal (None, 19, 19, 728)  2912        block6_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, 19, 19, 728)  0           block6_sepconv3_bn[0][0]         \n",
      "                                                                 add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1_act (Activation (None, 19, 19, 728)  0           add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1 (SeparableConv2 (None, 19, 19, 728)  536536      block7_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1_bn (BatchNormal (None, 19, 19, 728)  2912        block7_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2_act (Activation (None, 19, 19, 728)  0           block7_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2 (SeparableConv2 (None, 19, 19, 728)  536536      block7_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2_bn (BatchNormal (None, 19, 19, 728)  2912        block7_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3_act (Activation (None, 19, 19, 728)  0           block7_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3 (SeparableConv2 (None, 19, 19, 728)  536536      block7_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3_bn (BatchNormal (None, 19, 19, 728)  2912        block7_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_17 (Add)                    (None, 19, 19, 728)  0           block7_sepconv3_bn[0][0]         \n",
      "                                                                 add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1_act (Activation (None, 19, 19, 728)  0           add_17[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1 (SeparableConv2 (None, 19, 19, 728)  536536      block8_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1_bn (BatchNormal (None, 19, 19, 728)  2912        block8_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2_act (Activation (None, 19, 19, 728)  0           block8_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2 (SeparableConv2 (None, 19, 19, 728)  536536      block8_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2_bn (BatchNormal (None, 19, 19, 728)  2912        block8_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3_act (Activation (None, 19, 19, 728)  0           block8_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3 (SeparableConv2 (None, 19, 19, 728)  536536      block8_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3_bn (BatchNormal (None, 19, 19, 728)  2912        block8_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_18 (Add)                    (None, 19, 19, 728)  0           block8_sepconv3_bn[0][0]         \n",
      "                                                                 add_17[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1_act (Activation (None, 19, 19, 728)  0           add_18[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1 (SeparableConv2 (None, 19, 19, 728)  536536      block9_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1_bn (BatchNormal (None, 19, 19, 728)  2912        block9_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2_act (Activation (None, 19, 19, 728)  0           block9_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2 (SeparableConv2 (None, 19, 19, 728)  536536      block9_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2_bn (BatchNormal (None, 19, 19, 728)  2912        block9_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3_act (Activation (None, 19, 19, 728)  0           block9_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3 (SeparableConv2 (None, 19, 19, 728)  536536      block9_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3_bn (BatchNormal (None, 19, 19, 728)  2912        block9_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_19 (Add)                    (None, 19, 19, 728)  0           block9_sepconv3_bn[0][0]         \n",
      "                                                                 add_18[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1_act (Activatio (None, 19, 19, 728)  0           add_19[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1 (SeparableConv (None, 19, 19, 728)  536536      block10_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1_bn (BatchNorma (None, 19, 19, 728)  2912        block10_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2_act (Activatio (None, 19, 19, 728)  0           block10_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2 (SeparableConv (None, 19, 19, 728)  536536      block10_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2_bn (BatchNorma (None, 19, 19, 728)  2912        block10_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3_act (Activatio (None, 19, 19, 728)  0           block10_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3 (SeparableConv (None, 19, 19, 728)  536536      block10_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3_bn (BatchNorma (None, 19, 19, 728)  2912        block10_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_20 (Add)                    (None, 19, 19, 728)  0           block10_sepconv3_bn[0][0]        \n",
      "                                                                 add_19[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1_act (Activatio (None, 19, 19, 728)  0           add_20[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1 (SeparableConv (None, 19, 19, 728)  536536      block11_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1_bn (BatchNorma (None, 19, 19, 728)  2912        block11_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2_act (Activatio (None, 19, 19, 728)  0           block11_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2 (SeparableConv (None, 19, 19, 728)  536536      block11_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2_bn (BatchNorma (None, 19, 19, 728)  2912        block11_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3_act (Activatio (None, 19, 19, 728)  0           block11_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3 (SeparableConv (None, 19, 19, 728)  536536      block11_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3_bn (BatchNorma (None, 19, 19, 728)  2912        block11_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_21 (Add)                    (None, 19, 19, 728)  0           block11_sepconv3_bn[0][0]        \n",
      "                                                                 add_20[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1_act (Activatio (None, 19, 19, 728)  0           add_21[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1 (SeparableConv (None, 19, 19, 728)  536536      block12_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1_bn (BatchNorma (None, 19, 19, 728)  2912        block12_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2_act (Activatio (None, 19, 19, 728)  0           block12_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2 (SeparableConv (None, 19, 19, 728)  536536      block12_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2_bn (BatchNorma (None, 19, 19, 728)  2912        block12_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3_act (Activatio (None, 19, 19, 728)  0           block12_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3 (SeparableConv (None, 19, 19, 728)  536536      block12_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3_bn (BatchNorma (None, 19, 19, 728)  2912        block12_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_22 (Add)                    (None, 19, 19, 728)  0           block12_sepconv3_bn[0][0]        \n",
      "                                                                 add_21[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1_act (Activatio (None, 19, 19, 728)  0           add_22[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1 (SeparableConv (None, 19, 19, 728)  536536      block13_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1_bn (BatchNorma (None, 19, 19, 728)  2912        block13_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2_act (Activatio (None, 19, 19, 728)  0           block13_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2 (SeparableConv (None, 19, 19, 1024) 752024      block13_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2_bn (BatchNorma (None, 19, 19, 1024) 4096        block13_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 10, 10, 1024) 745472      add_22[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block13_pool (MaxPooling2D)     (None, 10, 10, 1024) 0           block13_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 10, 10, 1024) 4096        conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_23 (Add)                    (None, 10, 10, 1024) 0           block13_pool[0][0]               \n",
      "                                                                 batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1 (SeparableConv (None, 10, 10, 1536) 1582080     add_23[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1_bn (BatchNorma (None, 10, 10, 1536) 6144        block14_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1_act (Activatio (None, 10, 10, 1536) 0           block14_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2 (SeparableConv (None, 10, 10, 2048) 3159552     block14_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2_bn (BatchNorma (None, 10, 10, 2048) 8192        block14_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2_act (Activatio (None, 10, 10, 2048) 0           block14_sepconv2_bn[0][0]        \n",
      "==================================================================================================\n",
      "Total params: 20,861,480\n",
      "Trainable params: 20,806,952\n",
      "Non-trainable params: 54,528\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "xception (Model)             (None, 10, 10, 2048)      20861480  \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 204800)            0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               104858112 \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 5)                 2565      \n",
      "=================================================================\n",
      "Total params: 125,722,157\n",
      "Trainable params: 125,667,629\n",
      "Non-trainable params: 54,528\n",
      "_________________________________________________________________\n",
      "Found 2112 images belonging to 5 classes.\n",
      "Found 531 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "%config Completer.use_jedi = False\n",
    "\n",
    "\n",
    "\n",
    "conv_base = Xception(weights=\"imagenet\",include_top=False,input_shape=(299,299,3))\n",
    "conv_base.summary() # input 299,299,3\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(conv_base)\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(512,activation='relu'))\n",
    "model.add(layers.Dense(5, activation=\"softmax\"))\n",
    "model.summary()\n",
    "conv_base.trainable = False\n",
    "\n",
    "\n",
    "base_dir = \"./dataset_action/\"\n",
    "\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "validation_dir = os.path.join(base_dir, 'valid')\n",
    "\n",
    "\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "      rescale=1./255,\n",
    "      rotation_range=20,\n",
    "      width_shift_range=0.1,\n",
    "      height_shift_range=0.1,\n",
    "      shear_range=0.1,\n",
    "      zoom_range=0.1,\n",
    "      horizontal_flip=True,\n",
    "      fill_mode='nearest')\n",
    "\n",
    "# 검증 데이터는 증식되어서는 안 됩니다!\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        # 타깃 디렉터리\n",
    "        train_dir,\n",
    "        target_size=(299, 299),\n",
    "        batch_size=20,\n",
    "        class_mode='categorical')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        validation_dir,\n",
    "        target_size=(299, 299),\n",
    "        batch_size=20,\n",
    "        class_mode='categorical')\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=\"Adam\",\n",
    "              metrics=['acc'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "stone-drinking",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./dataset_action/train'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dedicated-brake",
   "metadata": {},
   "outputs": [
    {
     "ename": "UnidentifiedImageError",
     "evalue": "cannot identify image file <_io.BytesIO object at 0x0000024844E6F728>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnidentifiedImageError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-a2367170bfa1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_generator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m25\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\.conda\\envs\\python36\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32m~\\.conda\\envs\\python36\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    233\u001b[0m           \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m           \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 235\u001b[1;33m           use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    236\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    237\u001b[0m       \u001b[0mtotal_samples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_total_number_of_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_data_adapter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\python36\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36m_process_training_inputs\u001b[1;34m(model, x, y, batch_size, epochs, sample_weights, class_weights, steps_per_epoch, validation_split, validation_data, validation_steps, shuffle, distribution_strategy, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m    591\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    592\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 593\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    594\u001b[0m     \u001b[0mval_adapter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    595\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\python36\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36m_process_inputs\u001b[1;34m(model, mode, x, y, batch_size, epochs, sample_weights, class_weights, shuffle, steps, distribution_strategy, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m    704\u001b[0m       \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    705\u001b[0m       \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 706\u001b[1;33m       use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    707\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    708\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0madapter\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\python36\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, x, y, sample_weights, standardize_function, shuffle, workers, use_multiprocessing, max_queue_size, **kwargs)\u001b[0m\n\u001b[0;32m    950\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    951\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 952\u001b[1;33m         **kwargs)\n\u001b[0m\u001b[0;32m    953\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    954\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\python36\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, x, y, sample_weights, standardize_function, workers, use_multiprocessing, max_queue_size, **kwargs)\u001b[0m\n\u001b[0;32m    745\u001b[0m     \u001b[1;31m# Since we have to know the dtype of the python generator when we build the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    746\u001b[0m     \u001b[1;31m# dataset, we have to look at a batch to infer the structure.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 747\u001b[1;33m     \u001b[0mpeek\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_peek_and_restore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    748\u001b[0m     \u001b[0massert_not_namedtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpeek\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    749\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\python36\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36m_peek_and_restore\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    954\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    955\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_peek_and_restore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 956\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    957\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    958\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_make_callable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\python36\\lib\\site-packages\\keras_preprocessing\\image\\iterator.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     63\u001b[0m         index_array = self.index_array[self.batch_size * idx:\n\u001b[0;32m     64\u001b[0m                                        self.batch_size * (idx + 1)]\n\u001b[1;32m---> 65\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_batches_of_transformed_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex_array\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\python36\\lib\\site-packages\\keras_preprocessing\\image\\iterator.py\u001b[0m in \u001b[0;36m_get_batches_of_transformed_samples\u001b[1;34m(self, index_array)\u001b[0m\n\u001b[0;32m    228\u001b[0m                            \u001b[0mcolor_mode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolor_mode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    229\u001b[0m                            \u001b[0mtarget_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 230\u001b[1;33m                            interpolation=self.interpolation)\n\u001b[0m\u001b[0;32m    231\u001b[0m             \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimg_to_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_format\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    232\u001b[0m             \u001b[1;31m# Pillow images should be closed after `load_img`,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\python36\\lib\\site-packages\\keras_preprocessing\\image\\utils.py\u001b[0m in \u001b[0;36mload_img\u001b[1;34m(path, grayscale, color_mode, target_size, interpolation)\u001b[0m\n\u001b[0;32m    112\u001b[0m                           'The use of `load_img` requires PIL.')\n\u001b[0;32m    113\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 114\u001b[1;33m         \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpil_image\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    115\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcolor_mode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'grayscale'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m             \u001b[1;31m# if image is not already an 8-bit, 16-bit or 32-bit grayscale image\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\python36\\lib\\site-packages\\PIL\\Image.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(fp, mode, formats)\u001b[0m\n\u001b[0;32m   2957\u001b[0m         \u001b[0mwarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2958\u001b[0m     raise UnidentifiedImageError(\n\u001b[1;32m-> 2959\u001b[1;33m         \u001b[1;34m\"cannot identify image file %r\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mfilename\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2960\u001b[0m     )\n\u001b[0;32m   2961\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnidentifiedImageError\u001b[0m: cannot identify image file <_io.BytesIO object at 0x0000024844E6F728>"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_generator,steps_per_epoch=100,epochs=30,validation_data=validation_generator,validation_steps=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extra-values",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import callbacks\n",
    "base_dir = 'dataset_action/'\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "validation_dir = os.path.join(base_dir, 'valid')\n",
    "train_datagen = ImageDataGenerator(\n",
    "      rescale=1./255,\n",
    "      rotation_range=20,\n",
    "      width_shift_range=0.1,\n",
    "      height_shift_range=0.1,\n",
    "      shear_range=0.1,\n",
    "      zoom_range=0.1,\n",
    "      horizontal_flip=True,\n",
    "      fill_mode='nearest')\n",
    "# 검증 데이터는 증식되어서는 안 됩니다!\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        # 타깃 디렉터리\n",
    "        train_dir,\n",
    "        target_size=(299, 299),\n",
    "        batch_size=20,\n",
    "        class_mode='categorical')\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        validation_dir,\n",
    "        target_size=(299, 299),\n",
    "        batch_size=20,\n",
    "        class_mode='categorical')\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=\"Adam\",\n",
    "              metrics=['acc'])\n",
    "history = model.fit_generator(\n",
    "      train_generator,\n",
    "      steps_per_epoch=2000//20,\n",
    "      epochs=40,\n",
    "      validation_data=validation_generator,\n",
    "      validation_steps=500//20,\n",
    "      verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mysterious-field",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False\n",
    "from tensorflow.keras.applications.xception import Xception\n",
    "from tensorflow.keras.preprocessing import image\n",
    "conv_base = Xception(weights=\"imagenet\",include_top=False,input_shape=(299,299,3))\n",
    "conv_base.summary() # input 299,299,3\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "model = models.Sequential()\n",
    "model.add(conv_base)\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(256,activation='relu'))\n",
    "model.add(layers.Dense(5, activation=\"softmax\"))\n",
    "model.summary()\n",
    "conv_base.trainable = False\n",
    "import os\n",
    "import numpy as np\n",
    "base_dir = './dataset_action/'\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "validation_dir = os.path.join(base_dir, 'valid')\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "train_datagen = ImageDataGenerator(\n",
    "      rescale=1./255,\n",
    "      rotation_range=20,\n",
    "      width_shift_range=0.1,\n",
    "      height_shift_range=0.1,\n",
    "      shear_range=0.1,\n",
    "      zoom_range=0.1,\n",
    "      horizontal_flip=True,\n",
    "      fill_mode='nearest')\n",
    "# 검증 데이터는 증식되어서는 안 됩니다!\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        # 타깃 디렉터리\n",
    "        train_dir,\n",
    "        # 모든 이미지의 크기를 150 × 150로 변경합니다\n",
    "        target_size=(299, 299),\n",
    "        batch_size=20,\n",
    "        class_mode='categorical')\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        validation_dir,\n",
    "        target_size=(299, 299),\n",
    "        batch_size=20,\n",
    "        class_mode='categorical')\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=\"Adam\",\n",
    "              metrics=['acc'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "limiting-raleigh",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_generator,steps_per_epoch=80,epochs=30,validation_data=validation_generator,validation_steps=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "satellite-reporter",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
