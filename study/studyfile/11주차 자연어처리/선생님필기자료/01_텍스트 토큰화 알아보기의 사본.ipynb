{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mmXkXPSWs3yB"
   },
   "source": [
    "# Tokenization 이론\n",
    "토큰화란 텍스트에서 어디부터 어디까지가 문장이고, 무엇이 단어인지를 알려주는 것을 의미합니다. 보통 다음과 같은 토큰화 종류가 존재합니다.\n",
    "\n",
    "* 문장 토큰화\n",
    "* 단어 토큰화\n",
    "* subword 토큰화\n",
    "* 등등...\n",
    "\n",
    "토큰화된 문장을 토대로 여러가지 처리를 통해 기계가 텍스트를 인식할 수 있게 합니다!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YWd4-bdJuNj8"
   },
   "source": [
    "## #1. Tokenization for English\n",
    "영어를 토큰화 시키는 것은 한국어 보다 쉽습니다. 단순하게 띄어쓰기 또는 온점(.)을 기준으로 잘라내기만 하면 됩니다.\n",
    "\n",
    "스티비원더의 Isn't she Lovely 문장입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2LMAm2xiua-3"
   },
   "outputs": [],
   "source": [
    "sample_text = \"I never thought through love we'd be. Making one as lovely as she. But isn't she lovely made from love.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hA0mpkM2u9sD"
   },
   "source": [
    "위 문장을 **문장 토큰화(Sentence tokenization)** 시키면 다음과 같겠네요. 😄"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 898,
     "status": "ok",
     "timestamp": 1612851792158,
     "user": {
      "displayName": "Jong Hyeok Bae",
      "photoUrl": "",
      "userId": "02405125538750717072"
     },
     "user_tz": -540
    },
    "id": "XEfjLebvvFZz",
    "outputId": "f04848cc-7f98-4a45-e662-8c514466665c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"I never thought through love we'd be\",\n",
       " 'Making one as lovely as she',\n",
       " \"But isn't she lovely made from love.\"]"
      ]
     },
     "execution_count": 2,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_sentence = sample_text.split(\". \")\n",
    "tokenized_sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "49717UrdvL24"
   },
   "source": [
    "똑같은 문장을 **단어 토큰화(Word tokenization)** 시켜보겠습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "executionInfo": {
     "elapsed": 2271,
     "status": "ok",
     "timestamp": 1601802675462,
     "user": {
      "displayName": "소민호",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjD-HZUIiHV4BojBlitZCQyVN1l8bX1f0pFrPjt=s64",
      "userId": "13788803923072454204"
     },
     "user_tz": -540
    },
    "id": "prhn7U_4vmI6",
    "outputId": "710c8a39-827c-4b14-fcd7-029ad115c812"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I',\n",
       " 'never',\n",
       " 'thought',\n",
       " 'through',\n",
       " 'love',\n",
       " \"we'd\",\n",
       " 'be.',\n",
       " 'Making',\n",
       " 'one',\n",
       " 'as',\n",
       " 'lovely',\n",
       " 'as',\n",
       " 'she.',\n",
       " 'But',\n",
       " \"isn't\",\n",
       " 'she',\n",
       " 'lovely',\n",
       " 'made',\n",
       " 'from',\n",
       " 'love.']"
      ]
     },
     "execution_count": 3,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_word = sample_text.split()\n",
    "tokenized_word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I7fbfvlUvr6_"
   },
   "source": [
    "단순하게 띄어쓰기 기준으로 나눠보았는데요, 제대로 토큰화를 한다면 온점이나 어퍼스트로피(') 등은 다 제거해 주는게 좋겠죠? 사실 생각보다 토크나이징은 생각할 것이 많습니다 😅"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1MnDo0wp1zk4"
   },
   "source": [
    "### 1.1 띄어쓰기로 영어 문장 내 단어 구분하기\n",
    "문장 내에서 단어를 구분하는 여러 방법 중 띄어씌기를 이용해 구분하는 방법에 대해 이야기 해보겠습니다. 다음 **같은 의미**의 세 문장을 띄어쓰기로만 구분한다면 다음과 같습니다.\n",
    "\n",
    "* We're Genius!! ➡ `[\"We're\", \"Genius!!\"]`\n",
    "* We are Genius!! ➡ `[\"We\", \"are\", \"Genius!!\"]`\n",
    "* We are Genius ➡ `[\"We\", \"are\", \"Genius\"\"]`\n",
    "\n",
    "세 문장은 같은 의미 이지만, 결과가 다릅니다. 이는 우리가 원하는 형식의 토크나이징은 아닙니다😢. 즉 사람이 생각하기에는 세 문장을 모두 봐도 같은 의미라고 생각하지만, 기계는 그렇지 않다는 것이죠. 잘려진 토큰의 텍스트가 다르기 때문에 기계는 다르다고 생각합니다❌.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3N-aePYC_ntI"
   },
   "source": [
    "### 1.2 특수문자 제거를 이용해 단어 구분하기\n",
    "\n",
    "특수 문자를 모두 제거하면 해결될까요?\n",
    "\n",
    "* We're Genius!! ➡ `[\"We\", \"re\", \"Genius\"]`\n",
    "* We are Genius!! ➡ `[\"We\", \"are\", \"Genius\"]`\n",
    "* We are Genius ➡ `[\"We\", \"are\", \"Genius\"\"]`\n",
    "\n",
    "첫 번째 문장이 조금 거슬리긴 하지만 많이 좋아진 것도 같습니다. 하지만 특수 문자를 모두 제거하는 방법 또한 완벽한 방법이 아닙니다. 아래 예시를 보겠습니다.\n",
    "\n",
    "* $12.67 ➡ `[\"12\", \"67\"]`\n",
    "* Mr. So ➡ `[\"Mr\", \"So\"]`\n",
    "\n",
    "특수 문자를 제거하는 순간 본래의 의미를 잃어 버리게 됩니다. 단순한 텍스트의 리스트만 만들어 지네요☹️.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "611rCNNrC08Z"
   },
   "source": [
    "### 1.3 TreebankWordTokenizer 사용하기\n",
    "다행스럽게도 영어 단어 토크나이저 중 하나인 TreebankWordTokenizer라는 라이브러리가 있습니다. 표준 토큰화 규격이라고 할 수 있는 Penn Treebank Tokenization 규칙을 따라갑니다.\n",
    "\n",
    "TreebankWordTokenizer는 다음과 같은 규칙을 갖습니다.\n",
    "* 하이푼으로 구성된 단어는 하나로 유지한다.\n",
    "* doesn't와 같이 어포스트로피로 '접어'가 함께하는 단어는 분리해준다.\n",
    "\n",
    "다음과 같이 변환됩니다!\n",
    "\n",
    "* I don't care -> `['I', 'do', \"n't\", 'care', '!']`\n",
    "* Iron-Man is my favorite hero. -> `['Iron-Man', 'is', 'my', 'favorite', 'hero', '.']`\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WM-VWpFKDZuK"
   },
   "source": [
    "## #2. Tokenization for Korean (KoNLPy)\n",
    "기본적으로 한국어 토큰화가 영어 토큰화보다 난이도가 훨씬 높습니다😢. 띄어쓰기가 틀리거나 맞춤법이 틀려도 쉽게 읽을 수 있기 때문에 약간만 맞춤법이 틀려도 다른 단어로 인식되기가 쉽기 때문입니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eqA6jIjuWTSZ"
   },
   "source": [
    "### 2.1 한국어의 토큰화가 어려운 이유!\n",
    "\n",
    "한국어의 토큰화가 왜 어려운지 이야기 해보겠습니다😅.\n",
    "\n",
    "1. 한국어는 교착어이다.\n",
    "2. 한국어는 띄어쓰기가 잘 지켜지지 않는다.\n",
    "3. 한국어는 주어 생략은 물론 어순도 중요하지 않다.\n",
    "4. 한자어라는 특성상 하나의 음절조차도 다른 의미를 가질 수 있다.\n",
    "5. 그 외...\n",
    "\n",
    "지금 부터 한국어 토큰화가 왜 어려운지 알아보고, 한국어를 위한 토큰화 패키지는 무엇이 있는지 살펴보겠습니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q_9Pe8GrWGc3"
   },
   "source": [
    "#### 2.1.1 한국어는 교착어이다.\n",
    "**교착어**란 실질적인 의미를 가지는 어간에 조사나, 어미와 같은 문법 형태소들이 결합하여 **문법적인 기능**이 부여되는 **언어**를 의미합니다.\n",
    "\n",
    "가령, 한국어에는 영어권에는 없는 `은, 는, 이, 가, 을, 를, 에게, 에서...` 등과 같은 조사가 존재합니다.\n",
    "\n",
    "\n",
    "> **핸드폰을** 사자마자 **핸드폰에** 액정보호 필름을 붙이려다가 떨어뜨려서 **핸드폰의** 액정이 깨졌습니다. **핸드폰** 액정 수리비용 얼마죠? 눈물이 나네\n",
    "\n",
    "위 예시문을 단순하게 띄어쓰기 단위로 토큰화를 하게 되면 `핸드폰을`, `핸드폰에`, `핸드폰의`, `핸드폰`이 모두 다른 단어로 간주되어 버립니다.\n",
    "\n",
    "이를 처리하기 위해 주어나 목적어가 없으면 아무 의미를 가지지 못하는 조사들을 불용어(Stopword) 처리를 하기도 합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WMu3pzMyXLxI"
   },
   "source": [
    "#### 2.1.2 한국어는 띄어쓰기가 잘 지켜지지 않는다.\n",
    "한국어는 띄어쓰기가 어려운 편에 속하며, 띄어쓰기가 지켜지지 않더라도 쉽게 읽을 수 있습니다. 대부분의 데이터에서 띄어쓰기가 잘 지켜지지 않는 경향이 존재합니다.\n",
    "\n",
    "> 이렇게띄어쓰기를하지않아도일단은읽을수는있잖아요\n",
    "\n",
    "반면 영어는 띄어쓰기를 하지 않으면 읽기 어려운 언어의 특성으로 인해 띄어쓰기가 꽤나 엄격하게 지켜집니다\n",
    "\n",
    "> Yousugar,yespleaseWouldyoucomeandputitdownonme?\n",
    "\n",
    "\n",
    "그래서 보통 `py-hanspell` 패키지를 이용해 맞춤법 확인을 하거나 `ko-spacing` 패키지를 통해 띄어쓰기 교정을 진행합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PbfalhHPdemZ"
   },
   "source": [
    "#### 2.1.3 한국어는 주어 생략은 물론 어순도 중요하지 않다.\n",
    "\n",
    "이 뜻은 같은 의미의 문장을 자유롭게 어순을 바꿔서 쓸 수 있다는 이야기 입니다.\n",
    "\n",
    "> 1. 나는 운동을 했어. 체육관에서.\n",
    "2. 나는 체육관에서 운동을 했어.\n",
    "3. 체육관에서 운동했어.\n",
    "4. 나는 운동을 체육관에서 했어.\n",
    "\n",
    "이번 예시는 한국어를 사용함에 있어 잘못된 예시는 아니지만, 하나의 뜻을 여러 형태로 표현할 수 있다는 것에 주목해 주시면 됩니다😂."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ndfv3fRYkH28"
   },
   "source": [
    "#### 2.1.4 한자어라는 특성상 하나의 음절조차도 다른 의미를 가질 수 있다.\n",
    "\n",
    "예를 들어 `한국` 이라는 단어를 각각 음절 단위로 생각해 봤을 때 `한`,`국` 이라고 나뉘게 되는데요, `한`은 한자로 韓 으로 표현할 수 있지만 숫자 1이라고도 생각해 볼 수가 있죠, 마찬가지로 `국`도 한자어로 國 이라고 표현할 수 있지만 된장국, 미역국 처럼 우리가 먹는 국으로도 생각을 해버릴 수가 있게 됩니다.\n",
    "\n",
    "영어를 예시로 들었을 때 `Apple`을 `A, P, P, L, E`로 쪼갰다고 해서 `A`가 별다른 의미를 갖지는 않죠"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RZmYPzR2lkvj"
   },
   "source": [
    "### 2.2 한국어를 위한 토큰화 도구! 형태소 분석기를 소개합니다😍\n",
    "\n",
    "다양한 한국어 토크나이징을 위한 형태소 분석기가 존재합니다. 우리의 비즈니스에 맞게 알맞는 형태소 분석기를 사용할 수 있어요! 한국어를 위한 각종 형태소 분석기를 사용하기 위해서는 konlpy 패키지를 설치해야 합니다.\n",
    "\n",
    "```\n",
    "!pip install konlpy\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MxGXHRW-Duqo"
   },
   "source": [
    "#### 2.2.1 Mecab\n",
    "Mecab은 리눅스 시스템에서만 작동합니다. Windows에서는 사용하기가 매우 힘들기 때문에 구글 코랩이나 Mac, Linux에서만 사용해 주세요! Mecab은 다음 명령어를 이용해 설치할 수 있습니다. (코랩 기준)\n",
    "```\n",
    "!git clone https://github.com/SOMJANG/Mecab-ko-for-Google-Colab.git\n",
    "%cd Mecab-ko-for-Google-Colab\n",
    "!bash install_mecab-ko_on_colab190912.sh\n",
    "```\n",
    "\n",
    "Mecab은 실무에서 가장 많이 사용되고 있는 형태소 분석기 입니다\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AydO5GSYDue4"
   },
   "source": [
    "#### 2.2.2 Konlpy 패키지\n",
    "\n",
    "konlpy는 한글 형태소 분석을 위해 여러 패키지를 통합한 통합패키지 개념입니다.\n",
    "```\n",
    "!pip install konlpy\n",
    "```\n",
    "Twitter( Okt ), 꼬꼬마 (kkma), 코모란( komoran ), 한나눔( hannanum ) 패키지를 모두 포함하였습니다. 한글 텍스트를 처리 하기 위한 다양한 기능들과 효과등이 있습니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YjJO7uuUDuak"
   },
   "source": [
    "각 형태소 분석기는 결과물이 다르게 나옵니다. 따라서 여러분들의 비즈니스에 알맞는 형태소 분석기를 사용하면 될 것 같네요😃 \n",
    "\n",
    "예를 들어 속도가 중요하면 Mecab, 오탈자에 강건한 형태소 분석기를 원하면 Komoran을 선택할 수 있습니다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r3Jken4wNJlw"
   },
   "source": [
    "## #3. Cleaning(정제) and Normalization(정규화)\n",
    "**정제**란 불필요한 데이터를 제거하는 작업입니다. 텍스트 중간중간 껴있는 숫자나 필요없는 기호를 제거하거나, 한글의 경우 `은,는,이,가` 등은 비즈니스상 필요가 없을 수도 있습니다. 또는 띄어쓰기나 맞춤법을 확인해 깨끗한 데이터를 만들어 내는 작업도 포함됩니다. 정제 작업이란 다음과 같습니다.\n",
    "\n",
    "* 정규 표현식을 이용한 노이즈 데이터 제거\n",
    " - `Hmm... 포스터보고 초딩영화인줄.....오버연기조차 가볍지 않구나!!` -> `포스터보고 초딩영화인줄오버연기조차 가볍지 않구나`\n",
    "* 인코딩 문제 해결\n",
    " - 텍스트의 인코딩(utf-8, euc-kr 등)이 맞지 않으면 문자들이 깨지는 문제를 해결\n",
    "* 등장 빈도가 적은 단어 제거 (예 : 등장 빈도가 2회 이하면 단어를 제거해 주기 )\n",
    "* 길이가 짧은 단어의 제거\n",
    " - 영어의 경우 I, by, at 등을 제거\n",
    "* 불용어 제거\n",
    " - 영어의 경우 `the`는 거의 모든 텍스트 데이터에서 등장 빈도수가 많지만 실제 의미를 갖지 않기 때문에 제거\n",
    " - 한국어의 경우 `그럼, 위하, 때, 있, 그것, 사실, 경우, 어떤, 은, 는, 을, 를` 등이 존재\n",
    "\n",
    "**정규화**란 문장의 복잡도를 줄여주는 과정을 의미합니다. 같은 의미를 가지고 있는 여러 단어를 하나로 통합하는 등의 작업을 의미합니다. 형태소 분석의 의미 보다는 사람이 직접 판단을 해주는 일을 뜻합니다. 정규화 예시는 다음과 같습니다.\n",
    "* lemmatization\n",
    " - am, are, were, was --> be\n",
    " - has, had --> have \n",
    "* 10, 159, 123 -> num ( 숫자가 중요하지 않을 경우 )\n",
    "* ㅋ, ㅋㅋㅋ, ㅋㅋㅋㅋㅋ --> ㅋㅋ\n",
    "* Hmm, hmm, Hmmmmm --> hmm\n",
    "* 대소문자 통합 등"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AEur5wRqT0p9"
   },
   "source": [
    "### 3.1 한국어 정제를 위한 띄어쓰기 및 맞춤법 검사 패키지\n",
    "위에서도 잠시 설명했지만 한국어는 띄어쓰기와 맞춤법이 지켜지지 않는 경우가 꽤나 많기 다음 소개해 드릴 두 패키지를 이용해 한국어 정제 작업을 할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JIMVZ8AAloX3"
   },
   "source": [
    "#### 3.1.1 띄어쓰기를 보정해주는 KoSpacing 패키지\n",
    "잘못된 띄어쓰기를 보정해 주는 딥러닝 기반의 패키지 입니다. 다음은 예시입니다. \n",
    "```\n",
    "!pip install git+https://github.com/haven-jeon/PyKoSpacing.git\n",
    "```\n",
    "```\n",
    "4번놀고있지.4번은팀워크가없어.4번은개인주의야.4번은혼자밖에생각하지않아.\n",
    "```\n",
    "를 다음과 같이 바꿔줍니다\n",
    "```\n",
    "4번 놀고 있지.4번은 팀워크가 없어.4번은 개인주의야.4번은 혼자 밖에 생각하지 않아.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ijTtz8uNBXuN"
   },
   "source": [
    "#### 3.1.2 맞춤법 검사기 hanspell\n",
    "hanspell은 문장의 띄어쓰기 검사 및 맞춤법 검사를 손쉽게 수행할 수 있게 해줍니다. 설치 방법은 다음과 같습니다.\n",
    "\n",
    "```\n",
    "!pip install git+https://github.com/ssut/py-hanspell.git\n",
    "```\n",
    "\n",
    "또는\n",
    "\n",
    "```\n",
    "!git clone https://github.com/ssut/py-hanspell.git\n",
    "%cd py-hanspell/\n",
    "!python setup.py install\n",
    "```\n",
    "\n",
    "```\n",
    "맞춤법틀리면 외않되?\n",
    "```\n",
    "같은 엉망진창인 문장을\n",
    "```\n",
    "맞춤법 틀리면 왜 안돼?\n",
    "```\n",
    "로 예쁘게 바꿔줍니다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-nHJFjzaWPUz"
   },
   "source": [
    "# Tokenization 실습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0S610qXkXKsW"
   },
   "source": [
    "## 영어 토크나이저\n",
    "1. 영어 기본 토크나이저\n",
    "2. WordPunctTokenizer\n",
    "3. TreebankWordTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "executionInfo": {
     "elapsed": 4689,
     "status": "ok",
     "timestamp": 1601802677889,
     "user": {
      "displayName": "소민호",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjD-HZUIiHV4BojBlitZCQyVN1l8bX1f0pFrPjt=s64",
      "userId": "13788803923072454204"
     },
     "user_tz": -540
    },
    "id": "8k0RECJkYMKa",
    "outputId": "d8a63768-6d8d-4ffe-f08f-97f0cb404b85"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "sentence = \"Ain't nothin' sweeter, you want this sugar, don't ya?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0OkMw6KCYwiS"
   },
   "source": [
    "### 기본 토크나이저"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "executionInfo": {
     "elapsed": 4681,
     "status": "ok",
     "timestamp": 1601802677890,
     "user": {
      "displayName": "소민호",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjD-HZUIiHV4BojBlitZCQyVN1l8bX1f0pFrPjt=s64",
      "userId": "13788803923072454204"
     },
     "user_tz": -540
    },
    "id": "YJErRYJ2Y7KG",
    "outputId": "cf8c2c37-69c9-4773-beaa-df9a03e30e30"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Ai', \"n't\", 'nothin', \"'\", 'sweeter', ',', 'you', 'want', 'this', 'sugar', ',', 'do', \"n't\", 'ya', '?']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "print(word_tokenize(sentence))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lyFt0GI0YWk-"
   },
   "source": [
    "### WordPunkTokenizer\n",
    "아포스트로피(')가 들어간 상황에서 Ain't, don't 등은 어떻게 토큰화 시킬까요?😁"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "executionInfo": {
     "elapsed": 4673,
     "status": "ok",
     "timestamp": 1601802677891,
     "user": {
      "displayName": "소민호",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjD-HZUIiHV4BojBlitZCQyVN1l8bX1f0pFrPjt=s64",
      "userId": "13788803923072454204"
     },
     "user_tz": -540
    },
    "id": "IGHmfjkmYZv6",
    "outputId": "fdd0450c-250b-4f34-d067-8f1cf45610d6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Ain', \"'\", 't', 'nothin', \"'\", 'sweeter', ',', 'you', 'want', 'this', 'sugar', ',', 'don', \"'\", 't', 'ya', '?']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import WordPunctTokenizer\n",
    "print(WordPunctTokenizer().tokenize(sentence))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VYhLHZf9ZZ0U"
   },
   "source": [
    "### TreebankWordTokenizer\n",
    "Penn Treebank Tokenization 규칙이 적용 되었습니다. 다시 한번 규칙에 대해 알아보죠!\n",
    "1. 하이푼으로 구성된 단어는 하나로 유지한다.\n",
    "2. dosen't와 같이 아포스트로피로 접어가 함께하는 단어는 분리해 준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "executionInfo": {
     "elapsed": 4665,
     "status": "ok",
     "timestamp": 1601802677892,
     "user": {
      "displayName": "소민호",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjD-HZUIiHV4BojBlitZCQyVN1l8bX1f0pFrPjt=s64",
      "userId": "13788803923072454204"
     },
     "user_tz": -540
    },
    "id": "EqmhygX1ZoTr",
    "outputId": "28f24d32-0923-493c-b0c8-67edc711a1c1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Ai', \"n't\", 'nothin', \"'\", 'sweeter', ',', 'you', 'want', 'this', 'sugar', ',', 'do', \"n't\", 'ya', '?']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "tokenizer = TreebankWordTokenizer()\n",
    "print(tokenizer.tokenize(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "executionInfo": {
     "elapsed": 4656,
     "status": "ok",
     "timestamp": 1601802677893,
     "user": {
      "displayName": "소민호",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjD-HZUIiHV4BojBlitZCQyVN1l8bX1f0pFrPjt=s64",
      "userId": "13788803923072454204"
     },
     "user_tz": -540
    },
    "id": "SSXeG_crZxTf",
    "outputId": "e8149486-e35e-47d3-bbd2-5b9c441efe47"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', \"'m\", 'Iron-man']\n"
     ]
    }
   ],
   "source": [
    "sample_text = \"I'm Iron-man\"\n",
    "print(tokenizer.tokenize(sample_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5-HabBLhZ9e8"
   },
   "source": [
    "어떤 토크나이저를 사용해야 하는지는 중요하지 않습니다. 토크나이저마다 규칙이 다르기 때문에 여러분이 사용하고자 하는 목적에 따라 토크나이저를 선택하는 것이 중요하겠죠? 😀"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6SxgE1sWauzK"
   },
   "source": [
    "## 한글 토크나이저\n",
    "영어의 경우 사실 띄어쓰기로 토큰화를 하더라도 큰 문제가 발생하지 않습니다. 하지만 한국어는 영어보다 훨씬 복잡한 언어이기 때문에 형태소 분석기를 설치하고 이용해 보도록 하죠 😋"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 578
    },
    "executionInfo": {
     "elapsed": 11692,
     "status": "ok",
     "timestamp": 1601802684938,
     "user": {
      "displayName": "소민호",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjD-HZUIiHV4BojBlitZCQyVN1l8bX1f0pFrPjt=s64",
      "userId": "13788803923072454204"
     },
     "user_tz": -540
    },
    "id": "a0LxrI4IbEHo",
    "outputId": "99b9d8aa-cf0c-435a-9906-36a1b8a0daf1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting konlpy\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/85/0e/f385566fec837c0b83f216b2da65db9997b35dd675e107752005b7d392b1/konlpy-0.5.2-py2.py3-none-any.whl (19.4MB)\n",
      "\u001b[K     |████████████████████████████████| 19.4MB 30.7MB/s \n",
      "\u001b[?25hCollecting colorama\n",
      "  Downloading https://files.pythonhosted.org/packages/c9/dc/45cdef1b4d119eb96316b3117e6d5708a08029992b2fee2c143c7a0a5cc5/colorama-0.4.3-py2.py3-none-any.whl\n",
      "Collecting beautifulsoup4==4.6.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/d4/10f46e5cfac773e22707237bfcd51bbffeaf0a576b0a847ec7ab15bd7ace/beautifulsoup4-4.6.0-py3-none-any.whl (86kB)\n",
      "\u001b[K     |████████████████████████████████| 92kB 9.3MB/s \n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.6/dist-packages (from konlpy) (1.18.5)\n",
      "Collecting tweepy>=3.7.0\n",
      "  Downloading https://files.pythonhosted.org/packages/bb/7c/99d51f80f3b77b107ebae2634108717362c059a41384a1810d13e2429a81/tweepy-3.9.0-py2.py3-none-any.whl\n",
      "Collecting JPype1>=0.7.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8b/f7/a368401e630f0e390dd0e62c39fb928e5b23741b53c2360ee7d376660927/JPype1-1.0.2-cp36-cp36m-manylinux2010_x86_64.whl (3.8MB)\n",
      "\u001b[K     |████████████████████████████████| 3.8MB 46.4MB/s \n",
      "\u001b[?25hRequirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.6/dist-packages (from konlpy) (4.2.6)\n",
      "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (1.15.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (1.3.0)\n",
      "Requirement already satisfied: requests[socks]>=2.11.1 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (2.23.0)\n",
      "Requirement already satisfied: typing-extensions; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from JPype1>=0.7.0->konlpy) (3.7.4.3)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->tweepy>=3.7.0->konlpy) (3.1.0)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.24.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2020.6.20)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2.10)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6; extra == \"socks\" in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.7.1)\n",
      "Installing collected packages: colorama, beautifulsoup4, tweepy, JPype1, konlpy\n",
      "  Found existing installation: beautifulsoup4 4.6.3\n",
      "    Uninstalling beautifulsoup4-4.6.3:\n",
      "      Successfully uninstalled beautifulsoup4-4.6.3\n",
      "  Found existing installation: tweepy 3.6.0\n",
      "    Uninstalling tweepy-3.6.0:\n",
      "      Successfully uninstalled tweepy-3.6.0\n",
      "Successfully installed JPype1-1.0.2 beautifulsoup4-4.6.0 colorama-0.4.3 konlpy-0.5.2 tweepy-3.9.0\n"
     ]
    }
   ],
   "source": [
    "# konlpy 패키지 설치하기\n",
    "!pip install konlpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 157498,
     "status": "ok",
     "timestamp": 1601802830753,
     "user": {
      "displayName": "소민호",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjD-HZUIiHV4BojBlitZCQyVN1l8bX1f0pFrPjt=s64",
      "userId": "13788803923072454204"
     },
     "user_tz": -540
    },
    "id": "yutR1t5ibKYs",
    "outputId": "50e52283-c8e7-4266-9997-410249cebd20"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'Mecab-ko-for-Google-Colab'...\n",
      "remote: Enumerating objects: 60, done.\u001b[K\n",
      "remote: Counting objects: 100% (60/60), done.\u001b[K\n",
      "remote: Compressing objects: 100% (55/55), done.\u001b[K\n",
      "remote: Total 60 (delta 23), reused 20 (delta 5), pack-reused 0\u001b[K\n",
      "Unpacking objects: 100% (60/60), done.\n",
      "/content/Mecab-ko-for-Google-Colab\n",
      "Installing konlpy.....\n",
      "Requirement already satisfied: konlpy in /usr/local/lib/python3.6/dist-packages (0.5.2)\n",
      "Requirement already satisfied: colorama in /usr/local/lib/python3.6/dist-packages (from konlpy) (0.4.3)\n",
      "Requirement already satisfied: beautifulsoup4==4.6.0 in /usr/local/lib/python3.6/dist-packages (from konlpy) (4.6.0)\n",
      "Requirement already satisfied: tweepy>=3.7.0 in /usr/local/lib/python3.6/dist-packages (from konlpy) (3.9.0)\n",
      "Requirement already satisfied: JPype1>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from konlpy) (1.0.2)\n",
      "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.6/dist-packages (from konlpy) (4.2.6)\n",
      "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.6/dist-packages (from konlpy) (1.18.5)\n",
      "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (1.15.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (1.3.0)\n",
      "Requirement already satisfied: requests[socks]>=2.11.1 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (2.23.0)\n",
      "Requirement already satisfied: typing-extensions; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from JPype1>=0.7.0->konlpy) (3.7.4.3)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->tweepy>=3.7.0->konlpy) (3.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2020.6.20)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.24.3)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (3.0.4)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6; extra == \"socks\" in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.7.1)\n",
      "Done\n",
      "Installing mecab-0.996-ko-0.9.2.tar.gz.....\n",
      "Downloading mecab-0.996-ko-0.9.2.tar.gz.......\n",
      "from https://bitbucket.org/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz\n",
      "--2020-10-04 09:11:27--  https://bitbucket.org/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz\n",
      "Resolving bitbucket.org (bitbucket.org)... 18.205.93.0, 18.205.93.1, 18.205.93.2, ...\n",
      "Connecting to bitbucket.org (bitbucket.org)|18.205.93.0|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://bbuseruploads.s3.amazonaws.com/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz?Signature=lfHsN793rXogNJZi7OBaE5zi08k%3D&Expires=1601804422&AWSAccessKeyId=AKIA6KOSE3BNJRRFUUX6&versionId=null&response-content-disposition=attachment%3B%20filename%3D%22mecab-0.996-ko-0.9.2.tar.gz%22&response-content-encoding=None [following]\n",
      "--2020-10-04 09:11:27--  https://bbuseruploads.s3.amazonaws.com/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz?Signature=lfHsN793rXogNJZi7OBaE5zi08k%3D&Expires=1601804422&AWSAccessKeyId=AKIA6KOSE3BNJRRFUUX6&versionId=null&response-content-disposition=attachment%3B%20filename%3D%22mecab-0.996-ko-0.9.2.tar.gz%22&response-content-encoding=None\n",
      "Resolving bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)... 52.216.250.252\n",
      "Connecting to bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)|52.216.250.252|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1414979 (1.3M) [application/x-tar]\n",
      "Saving to: ‘mecab-0.996-ko-0.9.2.tar.gz’\n",
      "\n",
      "mecab-0.996-ko-0.9. 100%[===================>]   1.35M  3.42MB/s    in 0.4s    \n",
      "\n",
      "2020-10-04 09:11:28 (3.42 MB/s) - ‘mecab-0.996-ko-0.9.2.tar.gz’ saved [1414979/1414979]\n",
      "\n",
      "Done\n",
      "Unpacking mecab-0.996-ko-0.9.2.tar.gz.......\n",
      "Done\n",
      "Change Directory to mecab-0.996-ko-0.9.2.......\n",
      "installing mecab-0.996-ko-0.9.2.tar.gz........\n",
      "configure\n",
      "make\n",
      "make check\n",
      "make install\n",
      "ldconfig\n",
      "Done\n",
      "Change Directory to /content\n",
      "Downloading mecab-ko-dic-2.1.1-20180720.tar.gz.......\n",
      "from https://bitbucket.org/eunjeon/mecab-ko-dic/downloads/mecab-ko-dic-2.1.1-20180720.tar.gz\n",
      "--2020-10-04 09:12:55--  https://bitbucket.org/eunjeon/mecab-ko-dic/downloads/mecab-ko-dic-2.1.1-20180720.tar.gz\n",
      "Resolving bitbucket.org (bitbucket.org)... 18.205.93.1, 18.205.93.2, 18.205.93.0, ...\n",
      "Connecting to bitbucket.org (bitbucket.org)|18.205.93.1|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://bbuseruploads.s3.amazonaws.com/a4fcd83e-34f1-454e-a6ac-c242c7d434d3/downloads/b5a0c703-7b64-45ed-a2d7-180e962710b6/mecab-ko-dic-2.1.1-20180720.tar.gz?Signature=AqVn3Uo%2B7t82d5Q%2BQBLJjuHyvNs%3D&Expires=1601804504&AWSAccessKeyId=AKIA6KOSE3BNJRRFUUX6&versionId=tzyxc1TtnZU_zEuaaQDGN4F76hPDpyFq&response-content-disposition=attachment%3B%20filename%3D%22mecab-ko-dic-2.1.1-20180720.tar.gz%22&response-content-encoding=None [following]\n",
      "--2020-10-04 09:12:56--  https://bbuseruploads.s3.amazonaws.com/a4fcd83e-34f1-454e-a6ac-c242c7d434d3/downloads/b5a0c703-7b64-45ed-a2d7-180e962710b6/mecab-ko-dic-2.1.1-20180720.tar.gz?Signature=AqVn3Uo%2B7t82d5Q%2BQBLJjuHyvNs%3D&Expires=1601804504&AWSAccessKeyId=AKIA6KOSE3BNJRRFUUX6&versionId=tzyxc1TtnZU_zEuaaQDGN4F76hPDpyFq&response-content-disposition=attachment%3B%20filename%3D%22mecab-ko-dic-2.1.1-20180720.tar.gz%22&response-content-encoding=None\n",
      "Resolving bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)... 52.216.22.51\n",
      "Connecting to bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)|52.216.22.51|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 49775061 (47M) [application/x-tar]\n",
      "Saving to: ‘mecab-ko-dic-2.1.1-20180720.tar.gz’\n",
      "\n",
      "mecab-ko-dic-2.1.1- 100%[===================>]  47.47M  34.0MB/s    in 1.4s    \n",
      "\n",
      "2020-10-04 09:12:57 (34.0 MB/s) - ‘mecab-ko-dic-2.1.1-20180720.tar.gz’ saved [49775061/49775061]\n",
      "\n",
      "Done\n",
      "Unpacking  mecab-ko-dic-2.1.1-20180720.tar.gz.......\n",
      "Done\n",
      "Change Directory to mecab-ko-dic-2.1.1-20180720\n",
      "Done\n",
      "installing........\n",
      "configure\n",
      "make\n",
      "make install\n",
      "apt-get update\n",
      "apt-get upgrade\n",
      "apt install curl\n",
      "apt install git\n",
      "bash <(curl -s https://raw.githubusercontent.com/konlpy/konlpy/master/scripts/mecab.sh)\n",
      "Done\n",
      "Successfully Installed\n",
      "Now you can use Mecab\n",
      "from konlpy.tag import Mecab\n",
      "mecab = Mecab()\n"
     ]
    }
   ],
   "source": [
    "# Colab에 Mecab 설치하기 ( 시간이 좀 걸려요! )\n",
    "!git clone https://github.com/SOMJANG/Mecab-ko-for-Google-Colab.git\n",
    "%cd Mecab-ko-for-Google-Colab\n",
    "!bash install_mecab-ko_on_colab190912.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cLm18UqYbTXB"
   },
   "source": [
    "### konlpy 패키지 알아보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DvZB6xexct9V"
   },
   "outputs": [],
   "source": [
    "from konlpy.tag import Hannanum\n",
    "from konlpy.tag import Kkma\n",
    "from konlpy.tag import Komoran\n",
    "from konlpy.tag import Okt\n",
    "from konlpy.tag import Mecab\n",
    "\n",
    "hannanum = Hannanum()\n",
    "kkma = Kkma()\n",
    "komoran = Komoran()\n",
    "okt = Okt()\n",
    "mecab = Mecab()\n",
    "\n",
    "sentence = \"좋으니 그 사람 솔직히 견디기 버거워\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OU3XzDZcc_rD"
   },
   "source": [
    "#### 트위터( Okt )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "executionInfo": {
     "elapsed": 170463,
     "status": "ok",
     "timestamp": 1601802843734,
     "user": {
      "displayName": "소민호",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjD-HZUIiHV4BojBlitZCQyVN1l8bX1f0pFrPjt=s64",
      "userId": "13788803923072454204"
     },
     "user_tz": -540
    },
    "id": "V1baxh_cdGxI",
    "outputId": "4bdfcb76-74b4-4fec-f314-61aba83002c5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['그', '사람']\n",
      "['좋으니', '그', '사람', '솔직히', '견디기', '버거워']\n",
      "[('좋으니', 'Adjective'), ('그', 'Noun'), ('사람', 'Noun'), ('솔직히', 'Adjective'), ('견디기', 'Verb'), ('버거워', 'Adjective')]\n"
     ]
    }
   ],
   "source": [
    "print(okt.nouns(sentence))\n",
    "print(okt.morphs(sentence))\n",
    "print(okt.pos(sentence))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sTS8Rl5wdH63"
   },
   "source": [
    "#### 꼬꼬마( KKma )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "executionInfo": {
     "elapsed": 190039,
     "status": "ok",
     "timestamp": 1601802863319,
     "user": {
      "displayName": "소민호",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjD-HZUIiHV4BojBlitZCQyVN1l8bX1f0pFrPjt=s64",
      "userId": "13788803923072454204"
     },
     "user_tz": -540
    },
    "id": "slpiloypdRav",
    "outputId": "424af3dd-b074-4405-c892-f20673fbbea3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['사람']\n",
      "['좋', '으니', '그', '사람', '솔직히', '견디', '기', '버겁', '어']\n",
      "[('좋', 'VA'), ('으니', 'ECD'), ('그', 'MDT'), ('사람', 'NNG'), ('솔직히', 'MAG'), ('견디', 'VV'), ('기', 'ETN'), ('버겁', 'VA'), ('어', 'ECS')]\n"
     ]
    }
   ],
   "source": [
    "print(kkma.nouns(sentence))\n",
    "print(kkma.morphs(sentence))\n",
    "print(kkma.pos(sentence))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KJcAzxLedp8P"
   },
   "source": [
    "#### 코모란( Komoran )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "executionInfo": {
     "elapsed": 190031,
     "status": "ok",
     "timestamp": 1601802863320,
     "user": {
      "displayName": "소민호",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjD-HZUIiHV4BojBlitZCQyVN1l8bX1f0pFrPjt=s64",
      "userId": "13788803923072454204"
     },
     "user_tz": -540
    },
    "id": "bVefj7WMd1KV",
    "outputId": "e20d83e2-18ea-49a4-d6a8-14ca8eafe88f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['사람']\n",
      "['좋', '으니', '그', '사람', '솔직히', '견디', '기', '버거워']\n",
      "[('좋', 'VA'), ('으니', 'EC'), ('그', 'MM'), ('사람', 'NNG'), ('솔직히', 'MAG'), ('견디', 'VV'), ('기', 'ETN'), ('버거워', 'NA')]\n"
     ]
    }
   ],
   "source": [
    "print(komoran.nouns(sentence))\n",
    "print(komoran.morphs(sentence))\n",
    "print(komoran.pos(sentence))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "glspyEvid5Rv"
   },
   "source": [
    "#### 한나눔( Hannanum )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "executionInfo": {
     "elapsed": 192783,
     "status": "ok",
     "timestamp": 1601802866082,
     "user": {
      "displayName": "소민호",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjD-HZUIiHV4BojBlitZCQyVN1l8bX1f0pFrPjt=s64",
      "userId": "13788803923072454204"
     },
     "user_tz": -540
    },
    "id": "t74erCpOeH7Q",
    "outputId": "c4c79ac2-ebcd-4fb6-cfb6-f0d5c4f27047"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['사람', '버거워']\n",
      "['좋', '으니', '그', '사람', '솔직히', '견디', '기', '버거워']\n",
      "[('좋', 'P'), ('으니', 'E'), ('그', 'M'), ('사람', 'N'), ('솔직히', 'M'), ('견디', 'P'), ('기', 'E'), ('버거워', 'N')]\n"
     ]
    }
   ],
   "source": [
    "print(hannanum.nouns(sentence))\n",
    "print(hannanum.morphs(sentence))\n",
    "print(hannanum.pos(sentence))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZE4XVxBKeMnL"
   },
   "source": [
    "#### 메캅(Mecab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "executionInfo": {
     "elapsed": 192776,
     "status": "ok",
     "timestamp": 1601802866084,
     "user": {
      "displayName": "소민호",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjD-HZUIiHV4BojBlitZCQyVN1l8bX1f0pFrPjt=s64",
      "userId": "13788803923072454204"
     },
     "user_tz": -540
    },
    "id": "EQ1rNDyoeWIT",
    "outputId": "fb191650-b6a5-4a41-f93c-3826c184f279"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['사람']\n",
      "['좋', '으니', '그', '사람', '솔직히', '견디', '기', '버거워']\n",
      "[('좋', 'VA'), ('으니', 'EC'), ('그', 'MM'), ('사람', 'NNG'), ('솔직히', 'MAG'), ('견디', 'VV'), ('기', 'ETN'), ('버거워', 'VA+EC')]\n"
     ]
    }
   ],
   "source": [
    "print(mecab.nouns(sentence))\n",
    "print(mecab.morphs(sentence))\n",
    "print(mecab.pos(sentence))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LVAF-Cw-eYoQ"
   },
   "source": [
    "## 문장 토크나이징\n",
    "단순히 물음표, 온점, 느낌표 등으로 문장을 잘라내게 되면 문장을 토크나이징 할 수 있을까요? 꼭 그렇지만은 않습니다. ? 또는 !는 꽤나 정확하게 문장을 나눌 수 있는 기준이 되지만 온점(.)은 그렇지 못합니다.\n",
    "\n",
    "즉 온점은 문장의 끝이 아니더라도 올 수 있습니다.\n",
    "\n",
    "> **니 아이피 192.168.56.51 맞지? 거기 다운로드 폴더에 있는 모든 파일 압축해서 mhso.dev@kakao.com으로 보내줘.**\n",
    "\n",
    "> **Since I'm actively looking for Ph.D. students, I get the same question a dozen times every year.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JvBX8owSnMqk"
   },
   "source": [
    "### 영어 문장 토크나이징\n",
    "NLTK에서는 영어 문장의 토큰화를 수행하는 sent_tokenize를 지원하고 있습니다!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3tRspo5Nmn3l"
   },
   "outputs": [],
   "source": [
    "text = \"Since I'm actively looking for Ph.D. students. I get the same question a dozen times every year.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "executionInfo": {
     "elapsed": 192764,
     "status": "ok",
     "timestamp": 1601802866086,
     "user": {
      "displayName": "소민호",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjD-HZUIiHV4BojBlitZCQyVN1l8bX1f0pFrPjt=s64",
      "userId": "13788803923072454204"
     },
     "user_tz": -540
    },
    "id": "3kvUNxONmrmy",
    "outputId": "fbfd5ed6-ffb3-46f9-fd5a-5f10783afae1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Since I'm actively looking for Ph.D. students.\", 'I get the same question a dozen times every year.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "print(sent_tokenize(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "executionInfo": {
     "elapsed": 192755,
     "status": "ok",
     "timestamp": 1601802866086,
     "user": {
      "displayName": "소민호",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjD-HZUIiHV4BojBlitZCQyVN1l8bX1f0pFrPjt=s64",
      "userId": "13788803923072454204"
     },
     "user_tz": -540
    },
    "id": "iGe9T579mvCX",
    "outputId": "ee5ce8e6-4bde-4118-dd7e-2c98e74d1ea1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['My IP Address Is 192.168.56.51.', 'Send me this mail tommrrow']\n"
     ]
    }
   ],
   "source": [
    "text = \"My IP Address Is 192.168.56.51. Send me this mail tommrrow\"\n",
    "print(sent_tokenize(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pm-in1rKm58M"
   },
   "source": [
    "### 한국어 문장 토크나이징\n",
    "`kss` 패키지를 이용해 한국어 문장도 손쉽게 토크나이징이 가능합니다\n",
    "```\n",
    "!pip install kss\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "executionInfo": {
     "elapsed": 200733,
     "status": "ok",
     "timestamp": 1601802874073,
     "user": {
      "displayName": "소민호",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjD-HZUIiHV4BojBlitZCQyVN1l8bX1f0pFrPjt=s64",
      "userId": "13788803923072454204"
     },
     "user_tz": -540
    },
    "id": "kKPYYTy8nb33",
    "outputId": "0167430a-a44d-47ee-af1a-ab2055a670a7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting kss\n",
      "  Downloading https://files.pythonhosted.org/packages/fc/bb/4772901b3b934ac204f32a0bd6fc0567871d8378f9bbc7dd5fd5e16c6ee7/kss-1.3.1.tar.gz\n",
      "Building wheels for collected packages: kss\n",
      "  Building wheel for kss (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for kss: filename=kss-1.3.1-cp36-cp36m-linux_x86_64.whl size=251529 sha256=cdc013e99588db0418a5f88a0059a303724ccb66bd45a972456b9f16c7bc6efd\n",
      "  Stored in directory: /root/.cache/pip/wheels/8b/98/d1/53f75f89925cd95779824778725ee3fa36e7aa55ed26ad54a8\n",
      "Successfully built kss\n",
      "Installing collected packages: kss\n",
      "Successfully installed kss-1.3.1\n"
     ]
    }
   ],
   "source": [
    "!pip install kss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "executionInfo": {
     "elapsed": 200726,
     "status": "ok",
     "timestamp": 1601802874075,
     "user": {
      "displayName": "소민호",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjD-HZUIiHV4BojBlitZCQyVN1l8bX1f0pFrPjt=s64",
      "userId": "13788803923072454204"
     },
     "user_tz": -540
    },
    "id": "aL_legGjndF-",
    "outputId": "d08c2088-99d6-445b-c876-c9ca3e99fa75"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['내 아이피는 192.168.56.131 이에요.', '자연어 처리가 재미있으시죠?', '딥러닝으로 처리하면 더 재미있기는 합니다.', '근데 이거 너무 어려운거 아니냐?']\n"
     ]
    }
   ],
   "source": [
    "import kss\n",
    "text = \"내 아이피는 192.168.56.131 이에요. 자연어 처리가 재미있으시죠? 딥러닝으로 처리하면 더 재미있기는 합니다. 근데 이거 너무 어려운거 아니냐?\"\n",
    "print(kss.split_sentences(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n2cKjj6dnp6l"
   },
   "source": [
    "## 한국어 띄어쓰기 및 맞춤법 정리하기\n",
    "`kospacing`과 `hanspell`을 이용해 보겠습니다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pdotT5mzqqVc"
   },
   "source": [
    "### KoSpacing 설치 및 활용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 990
    },
    "executionInfo": {
     "elapsed": 205177,
     "status": "ok",
     "timestamp": 1601802878535,
     "user": {
      "displayName": "소민호",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjD-HZUIiHV4BojBlitZCQyVN1l8bX1f0pFrPjt=s64",
      "userId": "13788803923072454204"
     },
     "user_tz": -540
    },
    "id": "mWFUCYTVqsU9",
    "outputId": "363003f6-7c6e-4d4c-d33c-133f2e187ab3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/haven-jeon/PyKoSpacing.git\n",
      "  Cloning https://github.com/haven-jeon/PyKoSpacing.git to /tmp/pip-req-build-504jpnqg\n",
      "  Running command git clone -q https://github.com/haven-jeon/PyKoSpacing.git /tmp/pip-req-build-504jpnqg\n",
      "Requirement already satisfied: tensorflow>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from pykospacing==0.3) (2.3.0)\n",
      "Requirement already satisfied: keras>=2.4.3 in /usr/local/lib/python3.6/dist-packages (from pykospacing==0.3) (2.4.3)\n",
      "Requirement already satisfied: h5py>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from pykospacing==0.3) (2.10.0)\n",
      "Collecting argparse>=1.4.0\n",
      "  Downloading https://files.pythonhosted.org/packages/f2/94/3af39d34be01a24a6e65433d19e107099374224905f1e0cc6bbe1fd22a2f/argparse-1.4.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.3.0->pykospacing==0.3) (0.10.0)\n",
      "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.3.0->pykospacing==0.3) (1.6.3)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.3.0->pykospacing==0.3) (3.3.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.4.0,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.3.0->pykospacing==0.3) (2.3.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.3.0->pykospacing==0.3) (1.1.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.3.0->pykospacing==0.3) (3.12.4)\n",
      "Requirement already satisfied: scipy==1.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.3.0->pykospacing==0.3) (1.4.1)\n",
      "Requirement already satisfied: keras-preprocessing<1.2,>=1.1.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.3.0->pykospacing==0.3) (1.1.2)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.3.0->pykospacing==0.3) (1.32.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.3.0->pykospacing==0.3) (0.2.0)\n",
      "Requirement already satisfied: tensorboard<3,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.3.0->pykospacing==0.3) (2.3.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.3.0->pykospacing==0.3) (1.15.0)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.3.0->pykospacing==0.3) (1.12.1)\n",
      "Requirement already satisfied: numpy<1.19.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.3.0->pykospacing==0.3) (1.18.5)\n",
      "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.3.0->pykospacing==0.3) (0.35.1)\n",
      "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.3.0->pykospacing==0.3) (0.3.3)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras>=2.4.3->pykospacing==0.3) (3.13)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.9.2->tensorflow>=2.3.0->pykospacing==0.3) (50.3.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow>=2.3.0->pykospacing==0.3) (1.7.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow>=2.3.0->pykospacing==0.3) (2.23.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow>=2.3.0->pykospacing==0.3) (0.4.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow>=2.3.0->pykospacing==0.3) (1.0.1)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow>=2.3.0->pykospacing==0.3) (1.17.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow>=2.3.0->pykospacing==0.3) (3.2.2)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow>=2.3.0->pykospacing==0.3) (1.24.3)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow>=2.3.0->pykospacing==0.3) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow>=2.3.0->pykospacing==0.3) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow>=2.3.0->pykospacing==0.3) (2020.6.20)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow>=2.3.0->pykospacing==0.3) (1.3.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow>=2.3.0->pykospacing==0.3) (0.2.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow>=2.3.0->pykospacing==0.3) (4.1.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow>=2.3.0->pykospacing==0.3) (4.6)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow>=2.3.0->pykospacing==0.3) (2.0.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow>=2.3.0->pykospacing==0.3) (3.1.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow>=2.3.0->pykospacing==0.3) (0.4.8)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow>=2.3.0->pykospacing==0.3) (3.2.0)\n",
      "Building wheels for collected packages: pykospacing\n",
      "  Building wheel for pykospacing (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for pykospacing: filename=pykospacing-0.3-cp36-none-any.whl size=2255638 sha256=a2cebc2b8d350738f32a25f9856770461e8e5ccf88a6c37c5e89eea0e13a2f64\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-qbcv2c4p/wheels/4d/45/58/e26cb2b7f6a063d234158c6fd1e5700f6e15b99d67154340ba\n",
      "Successfully built pykospacing\n",
      "Installing collected packages: argparse, pykospacing\n",
      "Successfully installed argparse-1.4.0 pykospacing-0.3\n"
     ]
    },
    {
     "data": {
      "application/vnd.colab-display-data+json": {
       "pip_warning": {
        "packages": [
         "argparse"
        ]
       }
      }
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "!pip install git+https://github.com/haven-jeon/PyKoSpacing.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "executionInfo": {
     "elapsed": 219224,
     "status": "ok",
     "timestamp": 1601802892591,
     "user": {
      "displayName": "소민호",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjD-HZUIiHV4BojBlitZCQyVN1l8bX1f0pFrPjt=s64",
      "userId": "13788803923072454204"
     },
     "user_tz": -540
    },
    "id": "W5MOIgHYqyV_",
    "outputId": "d1a4e9fe-b444-41a0-80c4-da24658bd22f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4번 놀고 있지.4번은 팀워크가 없어.4번은 개인주의야.4번은 혼자 밖에 생각하지 않아.\n"
     ]
    }
   ],
   "source": [
    "from pykospacing import spacing\n",
    "\n",
    "text = \"4번놀고있지.4번은팀워크가없어.4번은개인주의야.4번은혼자밖에생각하지않아.\"\n",
    "spacing_text = spacing(text)\n",
    "print(spacing_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cx8CaF0ZrWgj"
   },
   "source": [
    "### hanspell 설치 및 활용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 272
    },
    "executionInfo": {
     "elapsed": 222957,
     "status": "ok",
     "timestamp": 1601802896333,
     "user": {
      "displayName": "소민호",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjD-HZUIiHV4BojBlitZCQyVN1l8bX1f0pFrPjt=s64",
      "userId": "13788803923072454204"
     },
     "user_tz": -540
    },
    "id": "liUmb3Xprh5W",
    "outputId": "ad2c83b5-ea87-4155-e115-fd88dc406f33"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/ssut/py-hanspell.git\n",
      "  Cloning https://github.com/ssut/py-hanspell.git to /tmp/pip-req-build-xz5l1axj\n",
      "  Running command git clone -q https://github.com/ssut/py-hanspell.git /tmp/pip-req-build-xz5l1axj\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from py-hanspell==1.1) (2.23.0)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->py-hanspell==1.1) (1.24.3)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->py-hanspell==1.1) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->py-hanspell==1.1) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->py-hanspell==1.1) (2020.6.20)\n",
      "Building wheels for collected packages: py-hanspell\n",
      "  Building wheel for py-hanspell (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for py-hanspell: filename=py_hanspell-1.1-cp36-none-any.whl size=4854 sha256=33f23a0a50c78827edd452fbfbe52cac7b4fd951b911276aef0eb6dfe05ddac7\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-qe6szidp/wheels/0a/25/d1/e5e96476dbb1c318cc26c992dd493394fe42b0c204b3e65588\n",
      "Successfully built py-hanspell\n",
      "Installing collected packages: py-hanspell\n",
      "Successfully installed py-hanspell-1.1\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/ssut/py-hanspell.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "executionInfo": {
     "elapsed": 223267,
     "status": "ok",
     "timestamp": 1601802896654,
     "user": {
      "displayName": "소민호",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjD-HZUIiHV4BojBlitZCQyVN1l8bX1f0pFrPjt=s64",
      "userId": "13788803923072454204"
     },
     "user_tz": -540
    },
    "id": "hQoaJuqYriJJ",
    "outputId": "60d45eca-dce8-4295-c9ed-8656c7bcddb3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "맞춤법 틀리면 왜 안돼?\n"
     ]
    }
   ],
   "source": [
    "from hanspell import spell_checker\n",
    "\n",
    "sent = \"맞춤법 틀리면 외 않되?\"\n",
    "spelled_sent = spell_checker.check(sent)\n",
    "\n",
    "hanspell_sent = spelled_sent.checked\n",
    "print(hanspell_sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G8un7Xp9rlpA"
   },
   "source": [
    "사실 hanspell은 맞춤법 교정 뿐만이 아닌 띄어쓰기 교정도 해줍니다 😄"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "executionInfo": {
     "elapsed": 223569,
     "status": "ok",
     "timestamp": 1601802896966,
     "user": {
      "displayName": "소민호",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjD-HZUIiHV4BojBlitZCQyVN1l8bX1f0pFrPjt=s64",
      "userId": "13788803923072454204"
     },
     "user_tz": -540
    },
    "id": "CWVEhh-Hrw9t",
    "outputId": "5126ba0c-584a-408c-ee3a-e6ed9ae338e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4번 놀고 있지.4번은 팀워크가 없어.4번은 개인주의야.4번은 혼자 밖에 생각하지 않아.\n",
      "4번 놀고 있지. 4번은 팀워크가 없어. 4번은 개인주의야. 4번은 혼자밖에 생각하지 않아.\n"
     ]
    }
   ],
   "source": [
    "text = \"4번놀고있지.4번은팀워크가없어.4번은개인주의야.4번은혼자밖에생각하지않아.\"\n",
    "\n",
    "kospacing_text = spacing(text)\n",
    "hanspell_text  = spell_checker.check(text).checked\n",
    "\n",
    "print(kospacing_text)\n",
    "print(hanspell_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F-SPzZH6toa6"
   },
   "source": [
    "## 텍스트 정규화\n",
    "텍스트 정규화(Text Normalization)은 통일 할 수 있는 단어를 하나로 통일하기 위한 전처리 과정입니다. 정규 표현식이나 사용자만의 규칙을 만들어 전처리할 수도 있지만 Stemming이나 Lemmatization도 활용합니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hMqdUL3cr7te"
   },
   "source": [
    "### 영어 정규화 - Stemming\n",
    "어간(Stem)을 추출하는 작업을 어간 추출(stemming)이라고 합니다. 어간 추출은 형태학적 분석을 단순화한 버전이라고 볼 수도 있고, 정해진 규칙만 보고 단어의 어미를 자르는 어림짐작의 작업이라고 볼 수도 있습니다. 다시 말해, 이 작업은 섬세한 작업이 아니기 때문에 **어간 추출 후에 나오는 결과 단어는 사전에 존재하지 않는 단어일 수도 있습니다.**\n",
    "\n",
    "가령, 포터 스테머의 포터 알고리즘의 어간 추출은 이러한 규칙들을 가집니다.\n",
    "* `Serialize` → `serial`\n",
    "* `Allowance` → `allow`\n",
    "* `Medical` → `medic`\n",
    "* `This` → `thi`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yO3m0wxlucSw"
   },
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "porterstemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "executionInfo": {
     "elapsed": 223549,
     "status": "ok",
     "timestamp": 1601802896968,
     "user": {
      "displayName": "소민호",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjD-HZUIiHV4BojBlitZCQyVN1l8bX1f0pFrPjt=s64",
      "userId": "13788803923072454204"
     },
     "user_tz": -540
    },
    "id": "0B2ie4DKu32b",
    "outputId": "d24e28dc-79e1-4b09-f1f5-52cf6d20c3cc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This', 'was', 'not', 'the', 'map', 'we', 'found', 'in', 'Billy', 'Bones', \"'s\", 'chest', ',', 'but', 'an', 'accurate', 'copy', ',', 'complete', 'in', 'all', 'things', '--', 'names', 'and', 'heights', 'and', 'soundings', '--', 'with', 'the', 'single', 'exception', 'of', 'the', 'red', 'crosses', 'and', 'the', 'written', 'notes', '.']\n"
     ]
    }
   ],
   "source": [
    "text = \"This was not the map we found in Billy Bones's chest, but an accurate copy, complete in all things--names and heights and soundings--with the single exception of the red crosses and the written notes.\"\n",
    "words = word_tokenize(text)\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "executionInfo": {
     "elapsed": 223537,
     "status": "ok",
     "timestamp": 1601802896968,
     "user": {
      "displayName": "소민호",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjD-HZUIiHV4BojBlitZCQyVN1l8bX1f0pFrPjt=s64",
      "userId": "13788803923072454204"
     },
     "user_tz": -540
    },
    "id": "Z9OMxPrTu7-A",
    "outputId": "33b18a23-74b1-489c-9a97-d60f39d41951"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['thi', 'wa', 'not', 'the', 'map', 'we', 'found', 'in', 'billi', 'bone', \"'s\", 'chest', ',', 'but', 'an', 'accur', 'copi', ',', 'complet', 'in', 'all', 'thing', '--', 'name', 'and', 'height', 'and', 'sound', '--', 'with', 'the', 'singl', 'except', 'of', 'the', 'red', 'cross', 'and', 'the', 'written', 'note', '.']\n"
     ]
    }
   ],
   "source": [
    "print([porterstemmer.stem(w) for w in words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "executionInfo": {
     "elapsed": 223527,
     "status": "ok",
     "timestamp": 1601802896969,
     "user": {
      "displayName": "소민호",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjD-HZUIiHV4BojBlitZCQyVN1l8bX1f0pFrPjt=s64",
      "userId": "13788803923072454204"
     },
     "user_tz": -540
    },
    "id": "gmgCEyrXu9oC",
    "outputId": "3d9eb530-03d5-4c3e-815b-e36977550be1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['serial', 'allow', 'medic', 'thi']\n"
     ]
    }
   ],
   "source": [
    "words=['Serialize', 'Allowance', 'Medical', 'This']\n",
    "print([porterstemmer.stem(w) for w in words])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GYACgurKvG0D"
   },
   "source": [
    "### 영어 정규화 - Lemmatization\n",
    "표제어 추출은 단어들이 다른 형태를 가지더라도, 그 뿌리 단어를 찾아가서 단어의 개수를 줄일 수 있는지 판단합니다. 예를 들어서 am, are, is는 서로 다른 스펠링이지만 그 뿌리 단어는 be라고 볼 수 있습니다. 이 때, 이 단어들의 표제어는 be라고 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "executionInfo": {
     "elapsed": 224188,
     "status": "ok",
     "timestamp": 1601802897643,
     "user": {
      "displayName": "소민호",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjD-HZUIiHV4BojBlitZCQyVN1l8bX1f0pFrPjt=s64",
      "userId": "13788803923072454204"
     },
     "user_tz": -540
    },
    "id": "cedRfpc4vWi8",
    "outputId": "5a4a1d06-57b3-4fe3-da25-7d5e3e0b4fb4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 31,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "executionInfo": {
     "elapsed": 226148,
     "status": "ok",
     "timestamp": 1601802899614,
     "user": {
      "displayName": "소민호",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjD-HZUIiHV4BojBlitZCQyVN1l8bX1f0pFrPjt=s64",
      "userId": "13788803923072454204"
     },
     "user_tz": -540
    },
    "id": "rc7fPV8wvcWD",
    "outputId": "bbcc5d0a-fcdc-4420-c45f-ca16872e3d56"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['policy', 'doing', 'organization', 'have', 'going', 'love', 'life', 'fly', 'dy', 'watched', 'ha', 'starting']\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "wordnetlemmatizer = WordNetLemmatizer()\n",
    "words=['policy', 'doing', 'organization', 'have', 'going', 'love', 'lives', 'fly', 'dies', 'watched', 'has', 'starting']\n",
    "print([wordnetlemmatizer.lemmatize(w) for w in words])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K0oEdAYNvfLn"
   },
   "source": [
    "### 한국어 정규화 - Stemming, Normalization\n",
    "형태소 분리기인 `Okt`에는 특정 단어의 어간을 추출하거나 정규화 시킬 수 있는 매개변수를 모두 제공합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "executionInfo": {
     "elapsed": 226138,
     "status": "ok",
     "timestamp": 1601802899616,
     "user": {
      "displayName": "소민호",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjD-HZUIiHV4BojBlitZCQyVN1l8bX1f0pFrPjt=s64",
      "userId": "13788803923072454204"
     },
     "user_tz": -540
    },
    "id": "TFI8CG_4v6Xo",
    "outputId": "00427adc-36df-4bbd-b067-c186560f3bbb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['4', '번', '놀고', '있지', '.', '4', '번은', '팀워크', '가', '없어', '.', '4', '번은', '개인주의', '야', '.', '4', '번은', '혼자', '밖에', '생각', '하지', '않아', '.']\n",
      "['4', '번', '놀다', '있다', '.', '4', '번은', '팀워크', '가', '없다', '.', '4', '번은', '개인주의', '야', '.', '4', '번은', '혼자', '밖에', '생각', '하다', '않다', '.']\n",
      "[('4', 'Number'), ('번', 'Noun'), ('놀고', 'Verb'), ('있지', 'Adjective'), ('.', 'Punctuation'), ('4', 'Number'), ('번은', 'Noun'), ('팀워크', 'Noun'), ('가', 'Josa'), ('없어', 'Adjective'), ('.', 'Punctuation'), ('4', 'Number'), ('번은', 'Noun'), ('개인주의', 'Noun'), ('야', 'Josa'), ('.', 'Punctuation'), ('4', 'Number'), ('번은', 'Noun'), ('혼자', 'Noun'), ('밖에', 'Josa'), ('생각', 'Noun'), ('하지', 'Verb'), ('않아', 'Verb'), ('.', 'Punctuation')]\n",
      "[('4', 'Number'), ('번', 'Noun'), ('놀다', 'Verb'), ('있다', 'Adjective'), ('.', 'Punctuation'), ('4', 'Number'), ('번은', 'Noun'), ('팀워크', 'Noun'), ('가', 'Josa'), ('없다', 'Adjective'), ('.', 'Punctuation'), ('4', 'Number'), ('번은', 'Noun'), ('개인주의', 'Noun'), ('야', 'Josa'), ('.', 'Punctuation'), ('4', 'Number'), ('번은', 'Noun'), ('혼자', 'Noun'), ('밖에', 'Josa'), ('생각', 'Noun'), ('하다', 'Verb'), ('않다', 'Verb'), ('.', 'Punctuation')]\n"
     ]
    }
   ],
   "source": [
    "text = \"4번 놀고 있지. 4번은 팀워크가 없어. 4번은 개인주의야. 4번은 혼자밖에 생각하지 않아.\"\n",
    "print(okt.morphs(text))\n",
    "print(okt.morphs(text, stem=True))\n",
    "print(okt.pos(text))\n",
    "print(okt.pos(text, stem=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "executionInfo": {
     "elapsed": 226128,
     "status": "ok",
     "timestamp": 1601802899617,
     "user": {
      "displayName": "소민호",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjD-HZUIiHV4BojBlitZCQyVN1l8bX1f0pFrPjt=s64",
      "userId": "13788803923072454204"
     },
     "user_tz": -540
    },
    "id": "TfhCVkoav7qL",
    "outputId": "455dc080-2f00-437f-d8c5-5557ee7e9222"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['웃기는', '소리', '하지마', '랔', 'ㅋㅋㅋ']\n",
      "['웃기는', '소리', '하지마라', 'ㅋㅋㅋ']\n",
      "[('웃기는', 'Verb'), ('소리', 'Noun'), ('하지마', 'Verb'), ('랔', 'Noun'), ('ㅋㅋㅋ', 'KoreanParticle')]\n",
      "[('웃기는', 'Verb'), ('소리', 'Noun'), ('하지마라', 'Verb'), ('ㅋㅋㅋ', 'KoreanParticle')]\n"
     ]
    }
   ],
   "source": [
    "text = \"웃기는 소리하지마랔ㅋㅋㅋ\"\n",
    "print(okt.morphs(text))\n",
    "print(okt.morphs(text, norm=True))\n",
    "print(okt.pos(text))\n",
    "print(okt.pos(text, norm=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ut5ljhxiw4bq"
   },
   "source": [
    "### 한국어 정규화 - 반복되는 문자 정제(soynlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "executionInfo": {
     "elapsed": 229636,
     "status": "ok",
     "timestamp": 1601802903138,
     "user": {
      "displayName": "소민호",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjD-HZUIiHV4BojBlitZCQyVN1l8bX1f0pFrPjt=s64",
      "userId": "13788803923072454204"
     },
     "user_tz": -540
    },
    "id": "PeSM9hEyxPGc",
    "outputId": "1e004703-ed06-4e8a-ef90-e92ca6c01453"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting soynlp\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7e/50/6913dc52a86a6b189419e59f9eef1b8d599cffb6f44f7bb91854165fc603/soynlp-0.0.493-py3-none-any.whl (416kB)\n",
      "\u001b[K     |████████████████████████████████| 419kB 4.4MB/s \n",
      "\u001b[?25hRequirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.6/dist-packages (from soynlp) (0.22.2.post1)\n",
      "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from soynlp) (1.4.1)\n",
      "Requirement already satisfied: psutil>=5.0.1 in /usr/local/lib/python3.6/dist-packages (from soynlp) (5.4.8)\n",
      "Requirement already satisfied: numpy>=1.12.1 in /usr/local/lib/python3.6/dist-packages (from soynlp) (1.18.5)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.20.0->soynlp) (0.16.0)\n",
      "Installing collected packages: soynlp\n",
      "Successfully installed soynlp-0.0.493\n"
     ]
    }
   ],
   "source": [
    "!pip install soynlp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8RKCEqcnxV8p"
   },
   "source": [
    "ㅋㅋ, ㅎㅎ 등의 이모티콘이 불필요하게 연속되는 경우가 꽤나 많습니다. 예를 들어 ㅋㅋㅋㅋㅋㅋ나 ㅎㅎㅎㅎㅎ 같은 이모티콘을 `soynlp`는 ㅋㅋ, ㅎㅎ 로 정규화 시켜주게 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "executionInfo": {
     "elapsed": 229625,
     "status": "ok",
     "timestamp": 1601802903139,
     "user": {
      "displayName": "소민호",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjD-HZUIiHV4BojBlitZCQyVN1l8bX1f0pFrPjt=s64",
      "userId": "13788803923072454204"
     },
     "user_tz": -540
    },
    "id": "7BOvSadExQf6",
    "outputId": "3fc4f8ee-494c-4313-c5a6-797f8c4cb107"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "아ㅋㅋ영화존잼쓰ㅠㅠ\n",
      "아ㅋㅋ영화존잼쓰ㅠㅠ\n",
      "아ㅋㅋ영화존잼쓰ㅠㅠ\n",
      "아ㅋㅋ영화존잼쓰ㅠㅠ\n"
     ]
    }
   ],
   "source": [
    "from soynlp.normalizer import *\n",
    "print(emoticon_normalize('앜ㅋㅋㅋㅋ이영화존잼쓰ㅠㅠㅠㅠㅠ', num_repeats=2))\n",
    "print(emoticon_normalize('앜ㅋㅋㅋㅋㅋㅋㅋㅋㅋ이영화존잼쓰ㅠㅠㅠㅠ', num_repeats=2))\n",
    "print(emoticon_normalize('앜ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ이영화존잼쓰ㅠㅠㅠㅠㅠㅠ', num_repeats=2))\n",
    "print(emoticon_normalize('앜ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ이영화존잼쓰ㅠㅠㅠㅠㅠㅠㅠㅠ', num_repeats=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5OtxQl94xU8y"
   },
   "source": [
    "이모티콘 뿐만이 아닌 의미없이 반복되는 텍스트도 줄여줄 수 있습니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "executionInfo": {
     "elapsed": 229615,
     "status": "ok",
     "timestamp": 1601802903140,
     "user": {
      "displayName": "소민호",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjD-HZUIiHV4BojBlitZCQyVN1l8bX1f0pFrPjt=s64",
      "userId": "13788803923072454204"
     },
     "user_tz": -540
    },
    "id": "Vw7GZ2R1xmgh",
    "outputId": "e9988928-c294-4def-9506-ff9428ddc4be"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "와하하핫\n",
      "와하하핫\n",
      "와하하핫\n"
     ]
    }
   ],
   "source": [
    "print(repeat_normalize('와하하하하하하하하하핫', num_repeats=2))\n",
    "print(repeat_normalize('와하하하하하하핫', num_repeats=2))\n",
    "print(repeat_normalize('와하하하하핫', num_repeats=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6QHDEClVxn0r"
   },
   "source": [
    "## 텍스트 정제"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GEHojAFIyYIP"
   },
   "source": [
    "### 영어 정규 표현식 정제\n",
    "영어 문장에서 알파벳만 추출하는 정규식 표현은 `a-zA-Z` 입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RBmvIab3yp65"
   },
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86
    },
    "executionInfo": {
     "elapsed": 229596,
     "status": "ok",
     "timestamp": 1601802903142,
     "user": {
      "displayName": "소민호",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjD-HZUIiHV4BojBlitZCQyVN1l8bX1f0pFrPjt=s64",
      "userId": "13788803923072454204"
     },
     "user_tz": -540
    },
    "id": "t8Li-R8YysVP",
    "outputId": "c8366fb0-b7e3-4573-c4c3-d4c225fa42f4"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "\"\\n\\n\\n\\n\\n\\n\\nYeah, do you expect people to read the FAQ, etc. and actually accept hard\\natheism?  No, you need a little leap of faith, Jimmy.  Your logic runs out\\nof steam!\\n\\n\\n\\n\\n\\n\\n\\nJim,\\n\\nSorry I can't pity you, Jim.  And I'm sorry that you have these feelings of\\ndenial about the faith you need to get by.  Oh well, just pretend that it will\\nall end happily ever after anyway.  Maybe if you start a new newsgroup,\\nalt.atheist.hard, you won't be bummin' so much?\\n\\n\\n\\n\\n\\n\\nBye-Bye, Big Jim.  Don't forget your Flintstone's Chewables!  :) \\n--\\nBake Timmons, III\""
      ]
     },
     "execution_count": 39,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eng_sent = \"\\n\\n\\n\\n\\n\\n\\nYeah, do you expect people to read the FAQ, etc. and actually accept hard\\natheism?  No, you need a little leap of faith, Jimmy.  Your logic runs out\\nof steam!\\n\\n\\n\\n\\n\\n\\n\\nJim,\\n\\nSorry I can't pity you, Jim.  And I'm sorry that you have these feelings of\\ndenial about the faith you need to get by.  Oh well, just pretend that it will\\nall end happily ever after anyway.  Maybe if you start a new newsgroup,\\nalt.atheist.hard, you won't be bummin' so much?\\n\\n\\n\\n\\n\\n\\nBye-Bye, Big Jim.  Don't forget your Flintstone's Chewables!  :) \\n--\\nBake Timmons, III\"\n",
    "eng_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86
    },
    "executionInfo": {
     "elapsed": 229586,
     "status": "ok",
     "timestamp": 1601802903142,
     "user": {
      "displayName": "소민호",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjD-HZUIiHV4BojBlitZCQyVN1l8bX1f0pFrPjt=s64",
      "userId": "13788803923072454204"
     },
     "user_tz": -540
    },
    "id": "SdiytLlKyslr",
    "outputId": "aca18436-ece2-4953-db2a-b22fa3896c5b"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'       Yeah  do you expect people to read the FAQ  etc  and actually accept hard atheism   No  you need a little leap of faith  Jimmy   Your logic runs out of steam         Jim   Sorry I can t pity you  Jim   And I m sorry that you have these feelings of denial about the faith you need to get by   Oh well  just pretend that it will all end happily ever after anyway   Maybe if you start a new newsgroup  alt atheist hard  you won t be bummin  so much        Bye Bye  Big Jim   Don t forget your Flintstone s Chewables          Bake Timmons  III'"
      ]
     },
     "execution_count": 40,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eng_sent = re.sub(\"[^a-zA-Z]\", \" \", eng_sent)\n",
    "eng_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "executionInfo": {
     "elapsed": 229577,
     "status": "ok",
     "timestamp": 1601802903143,
     "user": {
      "displayName": "소민호",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjD-HZUIiHV4BojBlitZCQyVN1l8bX1f0pFrPjt=s64",
      "userId": "13788803923072454204"
     },
     "user_tz": -540
    },
    "id": "zWO2pKrHyudH",
    "outputId": "02278d01-6ada-46f5-c7df-84355fc5b28a"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'Yeah expect people read actually accept hard atheism need little leap faith Jimmy Your logic runs steam Sorry pity sorry that have these feelings denial about faith need well just pretend that will happily ever after anyway Maybe start newsgroup atheist hard bummin much forget your Flintstone Chewables Bake Timmons'"
      ]
     },
     "execution_count": 41,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4글자 이상인 단어만 추출해서 새롭게 문장 만들기\n",
    "eng_sent = ' '.join([w for w in eng_sent.split() if len(w)>3])\n",
    "eng_sent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NBPzoIr7yweo"
   },
   "source": [
    "### 한국어 정규 표현식 정제\n",
    "한국어 문장에서 한글만 추출하는 정규식 표현은 `ㄱ-ㅎㅏ-ㅣ가-힣` 입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 229568,
     "status": "ok",
     "timestamp": 1601802903144,
     "user": {
      "displayName": "소민호",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjD-HZUIiHV4BojBlitZCQyVN1l8bX1f0pFrPjt=s64",
      "userId": "13788803923072454204"
     },
     "user_tz": -540
    },
    "id": "awElMr-6zE8x",
    "outputId": "2149cc6f-b984-4fc4-bb5b-1536baf91f9b"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'와 이런 것도 영화라고....ㅋㅋㅋ 차라리 뮤직비디오를 만드는 게 나을 뻔!!'"
      ]
     },
     "execution_count": 42,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kor_sent = \"와 이런 것도 영화라고....ㅋㅋㅋ 차라리 뮤직비디오를 만드는 게 나을 뻔!!\"\n",
    "kor_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 229558,
     "status": "ok",
     "timestamp": 1601802903144,
     "user": {
      "displayName": "소민호",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjD-HZUIiHV4BojBlitZCQyVN1l8bX1f0pFrPjt=s64",
      "userId": "13788803923072454204"
     },
     "user_tz": -540
    },
    "id": "C4Uo33qZzG1g",
    "outputId": "5302c717-0135-4c7d-c9c5-8aaadcb0d295"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'와 이런 것도 영화라고    ㅋㅋㅋ 차라리 뮤직비디오를 만드는 게 나을 뻔  '"
      ]
     },
     "execution_count": 43,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kor_sent = re.sub(\"[^ㄱ-ㅎㅏ-ㅣ가-힣]\", \" \", kor_sent)\n",
    "kor_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 229549,
     "status": "ok",
     "timestamp": 1601802903145,
     "user": {
      "displayName": "소민호",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjD-HZUIiHV4BojBlitZCQyVN1l8bX1f0pFrPjt=s64",
      "userId": "13788803923072454204"
     },
     "user_tz": -540
    },
    "id": "eFP9DWD7zHos",
    "outputId": "0d58b306-98af-4626-d8a3-75a82073052f"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'와 이런 것도 영화라고        차라리 뮤직비디오를 만드는 게 나을 뻔  '"
      ]
     },
     "execution_count": 44,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 완성형 한글만 남기는 경우\n",
    "kor_sent = re.sub(\"[^가-힣]\", \" \", kor_sent)\n",
    "kor_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 229539,
     "status": "ok",
     "timestamp": 1601802903145,
     "user": {
      "displayName": "소민호",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjD-HZUIiHV4BojBlitZCQyVN1l8bX1f0pFrPjt=s64",
      "userId": "13788803923072454204"
     },
     "user_tz": -540
    },
    "id": "deLJAd1XzJA9",
    "outputId": "5e993e24-df62-48f9-ed63-69136ce068f6"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'와 이런 것도 영화라고 차라리 뮤직비디오를 만드는 게 나을 뻔 '"
      ]
     },
     "execution_count": 45,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 띄어쓰기가 반복될 경우 1개로 줄인다.\n",
    "kor_sent = re.sub(\"[ ]{2,}\", \" \", kor_sent)\n",
    "kor_sent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F5bkY2-8zKN6"
   },
   "source": [
    "## Stopwords 설정하기\n",
    "영어에서의 I, my, me, over, the와 같은 단어들이나 한국어의 조사, 접미사 같은 단어들은 문장에서는 자주 등장하지만 실제 의미 분석을 하는데는 거의 기여하는 바가 없는 경우가 있습니다. 이러한 단어들을 불용어(stopword)라고 하며, NLTK에서는 위와 같은 100여개 이상의 영어 단어들을 불용어로 패키지 내에서 미리 정의하고 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VGLiDsx-3AHr"
   },
   "source": [
    "### 영어 stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "executionInfo": {
     "elapsed": 229530,
     "status": "ok",
     "timestamp": 1601802903146,
     "user": {
      "displayName": "소민호",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjD-HZUIiHV4BojBlitZCQyVN1l8bX1f0pFrPjt=s64",
      "userId": "13788803923072454204"
     },
     "user_tz": -540
    },
    "id": "vt2kMizF223X",
    "outputId": "73c2c9f2-a5a2-40c1-d94a-f10646ee7c46"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 46,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "executionInfo": {
     "elapsed": 229522,
     "status": "ok",
     "timestamp": 1601802903147,
     "user": {
      "displayName": "소민호",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjD-HZUIiHV4BojBlitZCQyVN1l8bX1f0pFrPjt=s64",
      "userId": "13788803923072454204"
     },
     "user_tz": -540
    },
    "id": "lp2XYQJT26Wt",
    "outputId": "c30c3f67-3787-4137-d2bc-c4d9084b4e25"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords  \n",
    "print(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "executionInfo": {
     "elapsed": 229512,
     "status": "ok",
     "timestamp": 1601802903147,
     "user": {
      "displayName": "소민호",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjD-HZUIiHV4BojBlitZCQyVN1l8bX1f0pFrPjt=s64",
      "userId": "13788803923072454204"
     },
     "user_tz": -540
    },
    "id": "iAck-9n82735",
    "outputId": "689e4aa9-de04-4716-cd0f-da0bb5303ab7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원문 : ['Family', 'is', 'not', 'an', 'important', 'thing', '.', 'It', \"'s\", 'everything', '.']\n",
      "불용어 제거 후 : ['Family', 'important', 'thing', '.', 'It', \"'s\", 'everything', '.']\n"
     ]
    }
   ],
   "source": [
    "example = \"Family is not an important thing. It's everything.\"\n",
    "stop_words = set(stopwords.words('english')) \n",
    "\n",
    "word_tokens = word_tokenize(example) # 먼저 토크나이징을 하고\n",
    "\n",
    "result = []\n",
    "for w in word_tokens: \n",
    "    if w not in stop_words: # 불용어 처리를 한다.\n",
    "        result.append(w) \n",
    "\n",
    "print('원문 :', word_tokens) \n",
    "print('불용어 제거 후 :', result) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y7yxf4m73DBB"
   },
   "source": [
    "### 한국어 stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 306
    },
    "executionInfo": {
     "elapsed": 232144,
     "status": "ok",
     "timestamp": 1601802905790,
     "user": {
      "displayName": "소민호",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjD-HZUIiHV4BojBlitZCQyVN1l8bX1f0pFrPjt=s64",
      "userId": "13788803923072454204"
     },
     "user_tz": -540
    },
    "id": "WvYFJpjn3Ipj",
    "outputId": "ca501591-c3f9-4dc6-f7fa-7357e28136f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: konlpy in /usr/local/lib/python3.6/dist-packages (0.5.2)\n",
      "Requirement already satisfied: colorama in /usr/local/lib/python3.6/dist-packages (from konlpy) (0.4.3)\n",
      "Requirement already satisfied: beautifulsoup4==4.6.0 in /usr/local/lib/python3.6/dist-packages (from konlpy) (4.6.0)\n",
      "Requirement already satisfied: JPype1>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from konlpy) (1.0.2)\n",
      "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.6/dist-packages (from konlpy) (4.2.6)\n",
      "Requirement already satisfied: tweepy>=3.7.0 in /usr/local/lib/python3.6/dist-packages (from konlpy) (3.9.0)\n",
      "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.6/dist-packages (from konlpy) (1.18.5)\n",
      "Requirement already satisfied: typing-extensions; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from JPype1>=0.7.0->konlpy) (3.7.4.3)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (1.3.0)\n",
      "Requirement already satisfied: requests[socks]>=2.11.1 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (2.23.0)\n",
      "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (1.15.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->tweepy>=3.7.0->konlpy) (3.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2020.6.20)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.24.3)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6; extra == \"socks\" in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.7.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install konlpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FunllQ_P3JdP"
   },
   "outputs": [],
   "source": [
    "from konlpy.tag import Okt\n",
    "okt = Okt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "executionInfo": {
     "elapsed": 232110,
     "status": "ok",
     "timestamp": 1601802905792,
     "user": {
      "displayName": "소민호",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjD-HZUIiHV4BojBlitZCQyVN1l8bX1f0pFrPjt=s64",
      "userId": "13788803923072454204"
     },
     "user_tz": -540
    },
    "id": "bv9nZ0T83M4n",
    "outputId": "3554675c-9ee8-4394-81d8-e6c343684eaa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['와', '이런', '것', '도', '영화', '라고', '차라리', '뮤직비디오', '를', '만드는', '게', '나을', '뻔']\n"
     ]
    }
   ],
   "source": [
    "example = \"와 이런 것도 영화라고 차라리 뮤직비디오를 만드는 게 나을 뻔\"\n",
    "word_tokens = okt.morphs(example)\n",
    "print(word_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "executionInfo": {
     "elapsed": 232095,
     "status": "ok",
     "timestamp": 1601802905792,
     "user": {
      "displayName": "소민호",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjD-HZUIiHV4BojBlitZCQyVN1l8bX1f0pFrPjt=s64",
      "userId": "13788803923072454204"
     },
     "user_tz": -540
    },
    "id": "VlVcgv-k3NFZ",
    "outputId": "b67117d9-af98-4dfb-b2ed-c6e69401c01a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원문 : ['와', '이런', '것', '도', '영화', '라고', '차라리', '뮤직비디오', '를', '만드는', '게', '나을', '뻔']\n",
      "불용어 제거 후 : ['이런', '영화', '라고', '차라리', '뮤직비디오', '만드는', '게', '나을', '뻔']\n"
     ]
    }
   ],
   "source": [
    "stop_words = ['의','가','이','은','들','는','좀','잘','걍','과','도','를','으로','자','에','와','한','하다', '것']\n",
    "# 위의 불용어는 임의로 선정한 것으로 실제 의미있는 선정 기준이 아니에요!\n",
    "# 일반적으로 조사나 접속사들이 불용어로 선정됩니다.\n",
    "\n",
    "result=[word for word in word_tokens if not word in stop_words]\n",
    "\n",
    "print('원문 :', word_tokens) \n",
    "print('불용어 제거 후 :', result) "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "01_텍스트 토큰화 알아보기의 사본",
   "provenance": [
    {
     "file_id": "1CRFVdNuCisGLe5w1BVk9HILVxMFhnfBY",
     "timestamp": 1612845573098
    }
   ],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
